{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce5c61c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cartopy.crs as ccrs\n",
    "import folium\n",
    "import pandas as pd\n",
    "import pypsa\n",
    "from pypsa.linopt import get_var, linexpr, define_constraints\n",
    "from geopy import distance\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f79feb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_network(years_select):\n",
    "    years_simulate = years_select\n",
    "    network = pypsa.Network(get_electrical_data(years_simulate))\n",
    "\n",
    "    return network\n",
    "\n",
    "\n",
    "def get_electrical_data(years_elect):\n",
    "    if years_elect == '2030':\n",
    "        return \"C:/Users/work/pypsa_thesis/data/electrical/2030\"\n",
    "    elif years_elect == '2040':\n",
    "        return \"C:/Users/work/pypsa_thesis/data/electrical/2040\"\n",
    "    elif years_elect == '2050':\n",
    "        return \"C:/Users/work/pypsa_thesis/data/electrical/2050\"\n",
    "\n",
    "\n",
    "def calculate_annuity(n, r):\n",
    "    \"\"\"Calculate the annuity factor for an asset with lifetime n years and\n",
    "    discount rate of r, e.g. annuity(20, 0.05) * 20 = 1.6\"\"\"\n",
    "\n",
    "    if isinstance(r, pd.Series):\n",
    "        return pd.Series(1 / n, index=r.index).where(r == 0, r / (1. - 1. / (1. + r) ** n))\n",
    "    elif r > 0:\n",
    "        return r / (1. - 1. / (1. + r) ** n)\n",
    "    else:\n",
    "        return 1 / n\n",
    "\n",
    "\n",
    "def get_techno_econ_data(n_years, years_data, discount_rate, network):\n",
    "    network = network\n",
    "    discount_rate = discount_rate\n",
    "    n_years = n_years\n",
    "\n",
    "    if years_data == '2030':\n",
    "        load_data = pd.read_csv(\"C:/Users/work/pypsa_thesis/data/techno_economic/pypsa_costs_2030.csv\")\n",
    "        df_load_data = pd.DataFrame(load_data)\n",
    "    elif years_data == '2040':\n",
    "        load_data = pd.read_csv(\"C:/Users/work/pypsa_thesis/data/techno_economic/pypsa_costs_2040.csv\")\n",
    "        df_load_data = pd.DataFrame(load_data)\n",
    "    elif years_data == '2050':\n",
    "        load_data = pd.read_csv(\"C:/Users/work/pypsa_thesis/data/techno_economic/pypsa_costs_2050.csv\")\n",
    "        df_load_data = pd.DataFrame(load_data)\n",
    "\n",
    "    # correct units to MW\n",
    "    df_load_data.loc[df_load_data.unit.str.contains(\"/kW\"), \"value\"] *= 1e3\n",
    "\n",
    "    df_tech_costs = pd.DataFrame(columns=['carriers', 'capital_costs', 'marginal_costs', 'efficiency', 'co2_emissions'])\n",
    "    df_tech_costs['carriers'] = list(network.carriers.index)\n",
    "    df_tech_costs.set_index('carriers', inplace=True)\n",
    "\n",
    "    for carrier_x in list(df_tech_costs.index):\n",
    "        if carrier_x != 'H2' or carrier_x != 'Water_Reservoir':\n",
    "            if carrier_x in list(df_load_data['technology']):\n",
    "                if carrier_x not in ('Solar', 'Wind_Offshore', 'Wind_Onshore', 'H2_(g)_pipeline'):\n",
    "                    df_cap_cost = pd.DataFrame(df_load_data[df_load_data['technology'] == carrier_x])\n",
    "                    lifetime = float(df_cap_cost[df_cap_cost['parameter'] == 'lifetime']['value'])\n",
    "                    FOM = float(df_cap_cost[df_cap_cost['parameter'] == 'FOM']['value'])\n",
    "                    investment = float(df_cap_cost[df_cap_cost['parameter'] == 'investment']['value'])\n",
    "                    efficiency_x = float(df_cap_cost[df_cap_cost['parameter'] == 'efficiency']['value'])\n",
    "                    df_tech_costs.at[carrier_x, 'capital_costs'] = round(((calculate_annuity(lifetime, discount_rate) +\n",
    "                                                                           FOM / 100.) *\n",
    "                                                                          investment * n_years), 2)\n",
    "                    df_tech_costs.at[carrier_x, 'efficiency'] = efficiency_x\n",
    "                else:\n",
    "                    df_cap_cost = pd.DataFrame(df_load_data[df_load_data['technology'] == carrier_x])\n",
    "                    lifetime = float(df_cap_cost[df_cap_cost['parameter'] == 'lifetime']['value'])\n",
    "                    FOM = float(df_cap_cost[df_cap_cost['parameter'] == 'FOM']['value'])\n",
    "                    investment = float(df_cap_cost[df_cap_cost['parameter'] == 'investment']['value'])\n",
    "                    df_tech_costs.at[carrier_x, 'capital_costs'] = round(((calculate_annuity(lifetime, discount_rate) +\n",
    "                                                                           FOM / 100.) *\n",
    "                                                                          investment * n_years), 2)\n",
    "                    df_tech_costs.at[carrier_x, 'efficiency'] = 1.0\n",
    "\n",
    "    for carrier_y in list(df_tech_costs.index):\n",
    "        if carrier_y in ('Biomass', 'CCGT', 'Coal', 'Lignite', 'Oil'):\n",
    "            if carrier_y == 'CCGT':\n",
    "                df_mar_cost = pd.DataFrame(df_load_data[df_load_data['technology'] == carrier_y])\n",
    "                VOM = float(df_mar_cost[df_mar_cost['parameter'] == 'VOM']['value'])\n",
    "                fuel = float(\n",
    "                    df_load_data[(df_load_data['parameter'] == 'fuel') & (df_load_data['technology'] == 'gas')][\n",
    "                        'value'])\n",
    "                efficiency_y = float(df_mar_cost[df_mar_cost['parameter'] == 'efficiency']['value'])\n",
    "                df_tech_costs.at[carrier_y, 'marginal_costs'] = round(VOM + fuel / efficiency_y, 2)\n",
    "            elif carrier_y == 'Biomass':\n",
    "                fuel = float(\n",
    "                    df_load_data[(df_load_data['parameter'] == 'fuel') & (df_load_data['technology'] == carrier_y)][\n",
    "                        'value'])\n",
    "                efficiency_y = float(df_load_data[(df_load_data['parameter'] == 'efficiency') & (\n",
    "                            df_load_data['technology'] == carrier_y)]['value'])\n",
    "                df_tech_costs.at[carrier_y, 'marginal_costs'] = round(fuel / efficiency_y, 2)\n",
    "            else:\n",
    "                df_mar_cost = pd.DataFrame(df_load_data[df_load_data['technology'] == carrier_y])\n",
    "                VOM = float(df_mar_cost[df_mar_cost['parameter'] == 'VOM']['value'])\n",
    "                fuel = float(df_mar_cost[df_mar_cost['parameter'] == 'fuel']['value'])\n",
    "                efficiency_y = float(df_mar_cost[df_mar_cost['parameter'] == 'efficiency']['value'])\n",
    "                df_tech_costs.at[carrier_y, 'marginal_costs'] = round(VOM + fuel / efficiency_y, 2)\n",
    "\n",
    "    for carrier_z in list(df_tech_costs.index):\n",
    "        if carrier_z in ('OCGT', 'CCGT', 'Coal', 'Lignite', 'Oil'):\n",
    "            if carrier_z == 'OCGT' or carrier_z == 'CCGT':\n",
    "                co2_intensity = float(df_load_data[(df_load_data['technology'] == 'Gas') & (df_load_data['parameter'] == 'CO2 intensity')][\n",
    "                    'value'])\n",
    "                df_tech_costs.at['{}'.format(carrier_z), 'co2_emissions'] = co2_intensity\n",
    "            else:\n",
    "                co2_intensity = float(df_load_data[(df_load_data['technology'] == '{}'.format(carrier_z)) & (df_load_data['parameter'] == 'CO2 intensity')][\n",
    "                    'value'])\n",
    "                df_tech_costs.at['{}'.format(carrier_z), 'co2_emissions'] = co2_intensity\n",
    "\n",
    "    df_tech_costs.fillna(0, inplace=True)\n",
    "\n",
    "    return df_tech_costs\n",
    "\n",
    "\n",
    "def get_hydrogen_data(scenario_h2, years_h2, h2_config, network):\n",
    "    network = network\n",
    "    if scenario_h2 == 'TN-H2-G':\n",
    "        if years_h2 == '2030':\n",
    "            load_data = pd.read_csv(\"C:/Users/work/pypsa_thesis/data/hydrogen/TN-H2-G/BW_2030.csv\",\n",
    "                                    index_col=0)\n",
    "\n",
    "        elif years_h2 == '2040':\n",
    "            load_data = pd.read_csv(\"C:/Users/work/pypsa_thesis/data/hydrogen/TN-H2-G/BW_2040.csv\",\n",
    "                                    index_col=0)\n",
    "\n",
    "        elif years_h2 == '2050':\n",
    "            load_data = pd.read_csv(\"C:/Users/work/pypsa_thesis/data/hydrogen/TN-H2-G/BW_2050.csv\",\n",
    "                                    index_col=0)\n",
    "\n",
    "    elif scenario_h2 == 'TN-PtG-PtL':\n",
    "        if years_h2 == '2030':\n",
    "            load_data = pd.read_csv(\"C:/Users/work/pypsa_thesis/data/hydrogen/TN-PtG-PtL/BW_2030.csv\",\n",
    "                                    index_col=0)\n",
    "\n",
    "        elif years_h2 == '2040':\n",
    "            load_data = pd.read_csv(\"C:/Users/work/pypsa_thesis/data/hydrogen/TN-PtG-PtL/BW_2040.csv\",\n",
    "                                    index_col=0)\n",
    "\n",
    "        elif years_h2 == '2050':\n",
    "            load_data = pd.read_csv(\"C:/Users/work/pypsa_thesis/data/hydrogen/TN-PtG-PtL/BW_2050.csv\",\n",
    "                                    index_col=0)\n",
    "\n",
    "    elif scenario_h2 == 'TN-Strom':\n",
    "        if years_h2 == '2030':\n",
    "            load_data = pd.read_csv(\"C:/Users/work/pypsa_thesis/data/hydrogen/TN-Strom/BW_2030.csv\",\n",
    "                                    index_col=0)\n",
    "\n",
    "        elif years_h2 == '2040':\n",
    "            load_data = pd.read_csv(\"C:/Users/work/pypsa_thesis/data/hydrogen/TN-Strom/BW_2040.csv\",\n",
    "                                    index_col=0)\n",
    "\n",
    "        elif years_h2 == '2050':\n",
    "            load_data = pd.read_csv(\"C:/Users/work/pypsa_thesis/data/hydrogen/TN-Strom/BW_2050.csv\",\n",
    "                                    index_col=0)\n",
    "\n",
    "    df_h2_demand = pd.DataFrame(load_data)\n",
    "    df_h2_demand.index.names = ['location_name']\n",
    "    df_h2_demand.reset_index(inplace=True)\n",
    "    df_h2_demand.dropna(subset=['location_name'], inplace=True)\n",
    "    x_coor = []\n",
    "    y_coor = []\n",
    "\n",
    "    for loc_count in range(len(df_h2_demand['location_name'])):\n",
    "        geolocator = Nominatim(user_agent=\"locate_h2_demand\")\n",
    "        locate_h2_demand = geolocator.geocode(df_h2_demand['location_name'][loc_count].split(',')[0])\n",
    "        x_coor.append(locate_h2_demand.longitude)\n",
    "        y_coor.append(locate_h2_demand.latitude)\n",
    "\n",
    "    df_h2_demand['x'] = x_coor\n",
    "    df_h2_demand['y'] = y_coor\n",
    "    df_ac_loads_h2_loads_dist = pd.DataFrame(index=network.loads.index, columns=df_h2_demand['location_name'])\n",
    "\n",
    "    for city_count_x in range(len(network.loads.index)):\n",
    "        for city_count_y in range(len(df_h2_demand['location_name'])):\n",
    "            if network.loads.index[city_count_x] != df_h2_demand['location_name'][city_count_y]:\n",
    "                city_1 = (network.loads['y'][city_count_x], network.loads['x'][city_count_x])\n",
    "                city_2 = (df_h2_demand['y'][city_count_y], df_h2_demand['x'][city_count_y])\n",
    "                dist_city1_city2 = distance.distance(city_1, city_2).km\n",
    "                df_ac_loads_h2_loads_dist.at[\n",
    "                    network.loads.index[city_count_x], df_h2_demand['location_name'][city_count_y]] = dist_city1_city2\n",
    "\n",
    "    ac_loads_h2_links = []\n",
    "\n",
    "    for column_count_x in df_ac_loads_h2_loads_dist.columns:\n",
    "        for distance_count_x in range(len(df_ac_loads_h2_loads_dist[column_count_x])):\n",
    "            if df_ac_loads_h2_loads_dist[column_count_x][distance_count_x] == \\\n",
    "                    df_ac_loads_h2_loads_dist[column_count_x].min():\n",
    "                ac_loads_h2_links.append(df_ac_loads_h2_loads_dist.index[distance_count_x])\n",
    "\n",
    "    ac_loads_h2_links = list(dict.fromkeys(ac_loads_h2_links))\n",
    "\n",
    "    df_h2_buses_load = pd.DataFrame(index=ac_loads_h2_links, columns={'h2_load': [], 'x': [], 'y': []})\n",
    "\n",
    "    for buses_count in range(len(network.buses.index)):\n",
    "        for h2_buses_count in range(len(df_h2_buses_load.index)):\n",
    "            if network.buses.index[buses_count] == df_h2_buses_load.index[h2_buses_count]:\n",
    "                df_h2_buses_load['x'][h2_buses_count] = network.buses['x'][buses_count]\n",
    "                df_h2_buses_load['y'][h2_buses_count] = network.buses['y'][buses_count]\n",
    "\n",
    "    df_h2_buses_load.fillna(0, inplace=True)\n",
    "\n",
    "    for column_count_y, i_count_y in zip(df_ac_loads_h2_loads_dist.columns, range(len(df_h2_demand['location_name']))):\n",
    "        for distance_count_y in range(len(df_ac_loads_h2_loads_dist[column_count_y])):\n",
    "            if df_ac_loads_h2_loads_dist[column_count_y][distance_count_y] == \\\n",
    "                    df_ac_loads_h2_loads_dist[column_count_y].min():\n",
    "                h2_load_value = df_h2_demand[df_h2_demand['location_name'] == column_count_y]['demand_value'][\n",
    "                                    i_count_y] * 1e6  # in MWh\n",
    "                h2_demand_loc = df_ac_loads_h2_loads_dist.index[distance_count_y]\n",
    "                if df_h2_buses_load.at[h2_demand_loc, 'h2_load'] == 0:\n",
    "                    df_h2_buses_load.at[h2_demand_loc, 'h2_load'] = h2_load_value\n",
    "                else:\n",
    "                    df_h2_buses_load.at[h2_demand_loc, 'h2_load'] = df_h2_buses_load.at[h2_demand_loc, 'h2_load'] + \\\n",
    "                                                                    h2_load_value\n",
    "\n",
    "    df_h2_pipelines_dist = pd.DataFrame(index=ac_loads_h2_links, columns=ac_loads_h2_links)\n",
    "\n",
    "    for column_count_z in range(len(list(df_h2_pipelines_dist.index))):\n",
    "        for row_count_z in range(len(list(df_h2_pipelines_dist.columns))):\n",
    "            if df_h2_pipelines_dist.index[column_count_z] != df_h2_pipelines_dist.columns[row_count_z]:\n",
    "                loc_1 = (df_h2_buses_load['y'][column_count_z], df_h2_buses_load['x'][column_count_z])\n",
    "                loc_2 = (df_h2_buses_load['y'][row_count_z], df_h2_buses_load['x'][row_count_z])\n",
    "                dist_loc_1_loc_2 = distance.distance(loc_1, loc_2).km\n",
    "                df_h2_pipelines_dist.at[\n",
    "                    df_h2_pipelines_dist.columns[row_count_z], df_h2_pipelines_dist.index[column_count_z]] = \\\n",
    "                    dist_loc_1_loc_2\n",
    "\n",
    "    if h2_config == 'short':\n",
    "\n",
    "        h2_pipe_row_list = []\n",
    "        h2_bus_0_list = []\n",
    "        h2_bus_1_list = []\n",
    "        bus_0_list = []\n",
    "        bus_1_list = []\n",
    "        distance_km_list = []\n",
    "\n",
    "        for city_count_p in list(df_h2_pipelines_dist.columns):\n",
    "            for city_count_q in range(len(list(df_h2_pipelines_dist.index))):\n",
    "                if df_h2_pipelines_dist[city_count_p][city_count_q] == \\\n",
    "                        df_h2_pipelines_dist[city_count_p].min():\n",
    "                    h2_pipe_row_list.append(\n",
    "                        '{}_{}_h2_pipe'.format(city_count_p, df_h2_pipelines_dist.index[city_count_q]))\n",
    "                    h2_bus_0_list.append('{}_H2_Bus'.format(city_count_p))\n",
    "                    h2_bus_1_list.append('{}_H2_Bus'.format(df_h2_pipelines_dist.index[city_count_q]))\n",
    "                    bus_0_list.append(city_count_p)\n",
    "                    bus_1_list.append(df_h2_pipelines_dist.index[city_count_q])\n",
    "                    distance_km_list.append(df_h2_pipelines_dist[city_count_p].min())\n",
    "\n",
    "        df_h2_pipelines = pd.DataFrame(index=h2_pipe_row_list)\n",
    "        df_h2_pipelines.index.names = ['H2_pipelines']\n",
    "\n",
    "        df_h2_pipelines['bus_0'] = h2_bus_0_list\n",
    "        df_h2_pipelines['bus_1'] = h2_bus_1_list\n",
    "        df_h2_pipelines['distance_km'] = distance_km_list\n",
    "\n",
    "        df_h2_pipelines.drop_duplicates(subset=['distance_km'], inplace=True)\n",
    "\n",
    "    elif h2_config == 'all':\n",
    "\n",
    "        h2_pipe_row_list = []\n",
    "        h2_bus_0_list = []\n",
    "        h2_bus_1_list = []\n",
    "        bus_0_list = []\n",
    "        bus_1_list = []\n",
    "        distance_km_list = []\n",
    "\n",
    "        for city_count_r in list(df_h2_pipelines_dist.columns):\n",
    "            for city_count_s, i_count_s in zip(list(df_h2_pipelines_dist.index),\n",
    "                                               range(len(list(df_h2_pipelines_dist.index)))):\n",
    "                if city_count_r != city_count_s:\n",
    "                    h2_pipe_row_list.append(\n",
    "                        '{}_{}_h2_pipe'.format(city_count_r, city_count_s))\n",
    "                    h2_bus_0_list.append('{}_H2_Bus'.format(city_count_r))\n",
    "                    h2_bus_1_list.append('{}_H2_Bus'.format(city_count_s))\n",
    "                    bus_0_list.append(city_count_r)\n",
    "                    bus_1_list.append(city_count_s)\n",
    "                    distance_km_list.append(df_h2_pipelines_dist[city_count_r][i_count_s])\n",
    "\n",
    "        df_h2_pipelines = pd.DataFrame(index=h2_pipe_row_list)\n",
    "        df_h2_pipelines.index.names = ['H2_pipelines']\n",
    "\n",
    "        df_h2_pipelines['bus_0'] = h2_bus_0_list\n",
    "        df_h2_pipelines['bus_1'] = h2_bus_1_list\n",
    "        df_h2_pipelines['distance_km'] = distance_km_list\n",
    "\n",
    "        df_h2_pipelines.drop_duplicates(subset=['distance_km'], inplace=True)\n",
    "\n",
    "    elif h2_config == 'short_fnb_2030':\n",
    "\n",
    "        h2_pipe_row_list = []\n",
    "        h2_bus_0_list = []\n",
    "        h2_bus_1_list = []\n",
    "        bus_0_list = []\n",
    "        bus_1_list = []\n",
    "        distance_km_list = []\n",
    "\n",
    "        for city_count_a in list(df_h2_pipelines_dist.columns):\n",
    "            for city_count_b in range(len(list(df_h2_pipelines_dist.index))):\n",
    "                if df_h2_pipelines_dist[city_count_a][city_count_b] == \\\n",
    "                        df_h2_pipelines_dist[city_count_a].min():\n",
    "                    h2_pipe_row_list.append(\n",
    "                        '{}_{}_h2_pipe'.format(city_count_a, df_h2_pipelines_dist.index[city_count_b]))\n",
    "                    h2_bus_0_list.append('{}_H2_Bus'.format(city_count_a))\n",
    "                    h2_bus_1_list.append('{}_H2_Bus'.format(df_h2_pipelines_dist.index[city_count_b]))\n",
    "                    bus_0_list.append(city_count_a)\n",
    "                    bus_1_list.append(df_h2_pipelines_dist.index[city_count_b])\n",
    "                    distance_km_list.append(df_h2_pipelines_dist[city_count_a].min())\n",
    "\n",
    "        # below connections currently only for BW, only applicable for TN-H2-G scenario\n",
    "        fnb_2030_add = [['Eichstetten_110kV', 'Lorrach_110kV'],\n",
    "                        ['KarlsruheWest_110kV', 'HeidelburgSud_110kV'],\n",
    "                        ['HeidelburgSud_110kV', 'Grossgartach_110kV'],\n",
    "                        ['Grossgartach_110kV', 'Kupferzell_110kV'],\n",
    "                        ['Sindelfingen_110kV', 'Birkenfeld_110kV'],\n",
    "                        ['Sindelfingen_110kV', 'Oberjettingen_110kV'],\n",
    "                        ['Reutlingen_110kV', 'Laufen_an_der_Eyach_110kV'],\n",
    "                        ['Sipplingen_110kV', 'Markdorf_110kV'],\n",
    "                        ['Biberach_110kV', 'Ravensburg_110kV'],\n",
    "                        ['Goldshofe_110kV', 'Giengen_110kV']]\n",
    "\n",
    "        for city_add in range(len(fnb_2030_add)):\n",
    "            h2_pipe_row_list.append('{}_{}_h2_pipe'.format(fnb_2030_add[city_add][0], fnb_2030_add[city_add][1]))\n",
    "            h2_bus_0_list.append('{}_H2_Bus'.format(fnb_2030_add[city_add][0]))\n",
    "            h2_bus_1_list.append('{}_H2_Bus'.format(fnb_2030_add[city_add][1]))\n",
    "            bus_0_list.append(fnb_2030_add[city_add][0])\n",
    "            distance_km_list.append(df_h2_pipelines_dist.at[fnb_2030_add[city_add][0], fnb_2030_add[city_add][1]])\n",
    "\n",
    "        df_h2_pipelines = pd.DataFrame(index=h2_pipe_row_list)\n",
    "        df_h2_pipelines.index.names = ['H2_pipelines']\n",
    "\n",
    "        df_h2_pipelines['bus_0'] = h2_bus_0_list\n",
    "        df_h2_pipelines['bus_1'] = h2_bus_1_list\n",
    "        df_h2_pipelines['distance_km'] = distance_km_list\n",
    "\n",
    "        df_h2_pipelines.drop_duplicates(subset=['distance_km'], inplace=True)\n",
    "\n",
    "    all_bus_list = bus_0_list + bus_1_list\n",
    "    connected_list = []\n",
    "\n",
    "    for city_check in ac_loads_h2_links:\n",
    "        if city_check not in all_bus_list:\n",
    "            print('{} not connected to any bus'.format(city_check))\n",
    "        else:\n",
    "            connected_list.append('{} is connected to a H2 bus'.format(city_check))\n",
    "\n",
    "    dict_h2_data = {'h2_links': ac_loads_h2_links,\n",
    "                    'h2_dataframe': df_h2_demand,\n",
    "                    'h2_buses_load': df_h2_buses_load,\n",
    "                    'h2_pipelines': df_h2_pipelines,\n",
    "                    'h2_demand_value_total': round(sum(df_h2_demand['demand_value']) * 1e6, 2)}  # in MWh\n",
    "\n",
    "    return dict_h2_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83df5fed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Case - 3 ###\n",
    "'''\n",
    "user input for:\n",
    "1) years to simulate\n",
    "2) which h2 demand scenario\n",
    "3) freq resolution in 1 year simulation - e.g. timesteps of: 24h / 12h / 6h / 1h \n",
    "4) annual discount rate of capital costs calculation for generators, storage units, electrolysis and H2 pipelines\n",
    "5) which h2 pipeline connection configuration (applicable for Case 3 only)\n",
    "'''\n",
    "\n",
    "years = '2030'  # subset of {'2030', '2040', '2050'}\n",
    "h2_scenario_demand = 'TN-H2-G'  # subset of {'TN-H2-G', 'TN-PtG-PtL', 'TN-Strom'}\n",
    "freq = '24'\n",
    "discount_rate = 0.07\n",
    "\n",
    "'''\n",
    "choose configuration of H2 pipelines connection (applicable for Case 3 only):\n",
    "1) 'short' - buses which have H2 demand (which are H2 buses), will connect to any H2 buses in the shortest distance\n",
    "2) 'all' - each H2 buses will connect to all other H2 buses regardless of short/long distances\n",
    "3) 'short_fnb_2030' - connects using 'short' config first and then follows roughly similar to proposed H2 pipeline\n",
    "                      connection based on FNB gas network development plan 2020 - 2030. This configuration currently\n",
    "                      LIMITED ONLY for 'TN-H2-G' H2 scenario demand \n",
    "                    \n",
    "'''\n",
    "h2_pipe_config = 'short_fnb_2030'\n",
    "\n",
    "### Case - 3 ###\n",
    "\n",
    "# get electrical network from network csv files; generators, storage_units, lines, loads & etc.\n",
    "# create snapshots based on chosen 'years' and timesteps 'freq' to simulate\n",
    "\n",
    "network = get_network(years)\n",
    "\n",
    "snapshots = pd.DatetimeIndex([])\n",
    "period = pd.date_range(start='{}-01-01 00:00'.format(years),\n",
    "                       freq='{}H'.format(freq),\n",
    "                       periods=8760 / float(freq))\n",
    "snapshots = snapshots.append(period)\n",
    "\n",
    "network.snapshots = pd.MultiIndex.from_arrays([snapshots.year, snapshots])\n",
    "\n",
    "Nyears = network.snapshot_weightings.objective.sum() / 8760\n",
    "\n",
    "'''\n",
    "\n",
    "Nyears value depends on the snapshot resolution freq variable\n",
    "Change of Nyears value will affect the calculation of capital cost based on pypsa-eur methodology from \n",
    "the add_electricity script\n",
    "\n",
    "Nyears = network.snapshot_weightings.objective.sum() / 8760\n",
    "Nyears\n",
    "\n",
    "costs[\"capital_cost\"] = ((annuity(costs[\"lifetime\"], costs[\"discount rate\"]) + \n",
    "                            costs[\"FOM\"]/100.) *\n",
    "                            costs[\"investment\"] * Nyears)\n",
    "\n",
    "'''\n",
    "# calls get_techno_econ_data function to calculate capital costs, marginal costs, efficiency for generators,\n",
    "# storage_units, electrolysis and H2 pipeline\n",
    "# the function depends on Nyears (changes with the input value of 'freq' timesteps), years, discount rate\n",
    "\n",
    "techno_econ_data = get_techno_econ_data(Nyears, years, discount_rate, network)\n",
    "\n",
    "# append capital costs, marginal costs, efficiency and co2 emissions into network generators, storage_units and carriers\n",
    "# from techno_econ_data\n",
    "\n",
    "# capital costs, marginal costs, efficiency for generators\n",
    "for x_carrier in list(techno_econ_data.index):\n",
    "    for y_carrier, y_loc in zip(list(network.generators['carrier']), list(network.generators.index)):\n",
    "        if x_carrier == y_carrier:\n",
    "            cap_cost_x = techno_econ_data.at['{}'.format(x_carrier), 'capital_costs']\n",
    "            mar_cost_x = techno_econ_data.at['{}'.format(x_carrier), 'marginal_costs']\n",
    "            gen_efficiency_x = techno_econ_data.at['{}'.format(x_carrier), 'efficiency']\n",
    "            network.generators.at['{}'.format(y_loc), 'capital_cost'] = cap_cost_x\n",
    "            network.generators.at['{}'.format(y_loc), 'marginal_cost'] = mar_cost_x\n",
    "            network.generators.at['{}'.format(y_loc), 'efficiency'] = gen_efficiency_x\n",
    "\n",
    "# capital costs, marginal costs, efficiency for storage units\n",
    "for p_carrier in list(techno_econ_data.index):\n",
    "    for q_carrier, q_loc in zip(list(network.storage_units['carrier']), list(network.storage_units.index)):\n",
    "        if p_carrier == q_carrier:\n",
    "            cap_cost_p = techno_econ_data.at['{}'.format(p_carrier), 'capital_costs']\n",
    "            mar_cost_p = techno_econ_data.at['{}'.format(p_carrier), 'marginal_costs']\n",
    "            gen_efficiency_p = techno_econ_data.at['{}'.format(p_carrier), 'efficiency']\n",
    "            network.storage_units.at['{}'.format(q_loc), 'capital_cost'] = cap_cost_p\n",
    "            network.storage_units.at['{}'.format(q_loc), 'marginal_cost'] = mar_cost_p\n",
    "            network.storage_units.at['{}'.format(q_loc), 'efficiency'] = gen_efficiency_p\n",
    "\n",
    "# co2 emissions for each carriers\n",
    "for r_carrier in list(techno_econ_data.index):\n",
    "    for s_carrier in list(network.carriers.index):\n",
    "        if r_carrier == s_carrier:\n",
    "            co2_emi = techno_econ_data.at['{}'.format(r_carrier), 'co2_emissions']\n",
    "            network.carriers.at['{}'.format(s_carrier), 'co2_emissions'] = co2_emi\n",
    "\n",
    "# current limitation #1: generates random p_max_pu values for renewable generators:\n",
    "# Solar, Wind Onshore and Wind Offshore\n",
    "\n",
    "pmaxpu_generators = network.generators[\n",
    "    (network.generators['carrier'] == 'Solar') |\n",
    "    (network.generators['carrier'] == 'Wind_Offshore') |\n",
    "    (network.generators['carrier'] == 'Wind_Onshore')]\n",
    "\n",
    "network.generators_t.p_max_pu = network.generators_t.p_max_pu.reindex(columns=pmaxpu_generators.index)\n",
    "\n",
    "network.generators_t.p_max_pu.loc[:, pmaxpu_generators.index] = pd.DataFrame(index=network.snapshots,\n",
    "                                                                             columns=pmaxpu_generators.index,\n",
    "                                                                             data=np.random.rand(len(network.snapshots),\n",
    "                                                                                                 len(pmaxpu_generators)))\n",
    "\n",
    "# calls get_hydrogen_data function to:\n",
    "# acquire H2 demand data based on chosen H2 scenario demand 'h2_scenario_demand' and 'years' to simulate\n",
    "# builds H2 pipeline configuration based on chosen H2 pipeline configuration 'h2_pipe_config\n",
    "\n",
    "h2_data = get_hydrogen_data(h2_scenario_demand, years, h2_pipe_config, network)\n",
    "\n",
    "# builds and connects H2 network with Electrical Buses/Nodes network\n",
    "\n",
    "df_h2_buses_load = pd.DataFrame(h2_data['h2_buses_load'])  # dataframe of H2 demand for each H2 Buses/Loads\n",
    "df_h2_pipes = pd.DataFrame(h2_data['h2_pipelines'])  # dataframe of H2 pipeline connections between H2 Buses\n",
    "\n",
    "# creates H2 Buses\n",
    "\n",
    "h2_buses_names = list(df_h2_buses_load.index)\n",
    "\n",
    "h2_buses = [x + '_H2_Bus' for x in h2_buses_names]\n",
    "\n",
    "network.madd('Bus',\n",
    "             h2_buses,\n",
    "             carrier='H2',\n",
    "             x=list(df_h2_buses_load['x']),\n",
    "             y=list(df_h2_buses_load['y'])\n",
    "             )\n",
    "\n",
    "# electrolysis capital cost and efficiency are based on DEA agency data and pypsa methodology calculations\n",
    "\n",
    "electrolysis_cap_cost = techno_econ_data.at['Electrolysis', 'capital_costs']\n",
    "electrolysis_efficiency = techno_econ_data.at['Electrolysis', 'efficiency']\n",
    "\n",
    "# electrolysis_cap_cost = 0\n",
    "# electrolysis_efficiency = 1\n",
    "\n",
    "h2_links = [s + '_Electrolysis' for s in h2_buses_names]\n",
    "\n",
    "# connects Electrical Buses/Nodes with H2 Buses using Electrolysis Links\n",
    "\n",
    "network.madd('Link',\n",
    "             h2_links,\n",
    "             carrier='H2',\n",
    "             capital_cost=electrolysis_cap_cost,\n",
    "             p_nom_extendable=True,\n",
    "             bus0=h2_buses_names,\n",
    "             bus1=h2_buses,\n",
    "             efficiency=electrolysis_efficiency)\n",
    "\n",
    "h2_pipe_cap_cost = techno_econ_data.at['H2_(g)_pipeline', 'capital_costs']\n",
    "h2_pipe_efficiency = techno_econ_data.at['H2_(g)_pipeline', 'efficiency']\n",
    "\n",
    "# h2_pipe_cap_cost = 0\n",
    "# h2_pipe_efficiency = 1\n",
    "\n",
    "# attach and connect H2 pipelines between the H2 buses\n",
    "\n",
    "network.madd('Link',\n",
    "             df_h2_pipes.index,\n",
    "             bus0=list(df_h2_pipes['bus_0']),\n",
    "             bus1=list(df_h2_pipes['bus_1']),\n",
    "             p_min_pu=-1,\n",
    "             p_nom_extendable=True,\n",
    "             length=list(df_h2_pipes['distance_km']),\n",
    "             capital_cost=h2_pipe_cap_cost * df_h2_pipes['distance_km'],\n",
    "             efficiency=h2_pipe_efficiency,\n",
    "             carrier='H2')\n",
    "\n",
    "# attach H2 Stores to H2 Buses\n",
    "\n",
    "h2_stores = [y + '_H2_Store' for y in h2_buses_names]\n",
    "\n",
    "network.madd('Store',\n",
    "             h2_stores,\n",
    "             bus=h2_buses,\n",
    "             carrier='H2',\n",
    "             e_nom_extendable=True)\n",
    "\n",
    "# attach H2 Loads to H2 Buses\n",
    "\n",
    "h2_loads = [z + '_H2_Load' for z in h2_buses_names]\n",
    "\n",
    "'''\n",
    "# static H2 load and series AC load\n",
    "network.madd('Load',\n",
    "             h2_loads,\n",
    "             bus=h2_buses,\n",
    "             p_set=list(df_h2_buses_load['h2_load']),\n",
    "             carrier='Hydrogen',\n",
    "             x=list(df_h2_buses_load['x']),\n",
    "             y=list(df_h2_buses_load['y'])\n",
    "             )\n",
    "\n",
    "ac_loads = network.loads[(network.loads['carrier'] == 'AC')]\n",
    "\n",
    "network.loads_t.p_set = pd.DataFrame(index=network.snapshots,\n",
    "                                     columns=ac_loads.index,\n",
    "                                     data=1000 * np.random.rand(len(network.snapshots), len(ac_loads)))\n",
    "'''\n",
    "# series AC and H2 load\n",
    "\n",
    "network.madd('Load',\n",
    "             h2_loads,\n",
    "             bus=h2_buses,\n",
    "             carrier='H2',\n",
    "             x=list(df_h2_buses_load['x']),\n",
    "             y=list(df_h2_buses_load['y'])\n",
    "             )\n",
    "\n",
    "# current limitation #2: generates random AC loads/demand for Electrical Buses/Nodes\n",
    "\n",
    "ac_loads = network.loads[(network.loads['carrier'] == 'AC')]\n",
    "\n",
    "ac_loads_p_set = pd.DataFrame(index=network.snapshots,\n",
    "                              columns=ac_loads.index,\n",
    "                              data=1000 * np.random.rand(len(network.snapshots), len(ac_loads)))\n",
    "\n",
    "# H2 loads set in series, based on Fraunhofer data\n",
    "\n",
    "df_h2_p_set = pd.DataFrame(index=network.snapshots, columns=h2_loads)\n",
    "\n",
    "for i_load in range(len(df_h2_p_set.columns)):\n",
    "    df_h2_p_set['{}'.format(df_h2_p_set.columns[i_load])] = df_h2_buses_load['h2_load'][i_load] / len(network.snapshots)\n",
    "\n",
    "# merge series of AC loads and H2 loads\n",
    "\n",
    "network.loads_t.p_set = pd.merge(ac_loads_p_set, df_h2_p_set, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb2adb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for electrolysis\n",
    "\n",
    "elec_list = []\n",
    "\n",
    "for y in network.links.index:\n",
    "    if '_Electrolysis' in y.split('110kV'):\n",
    "        elec_list.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbee3c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for h2 pipes\n",
    "\n",
    "h2_pipe_list = []\n",
    "for x in network.links.index:\n",
    "    if '_h2_pipe' in x.split('110kV'):\n",
    "        h2_pipe_list.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a9fe93",
   "metadata": {},
   "outputs": [],
   "source": [
    "elec_list = pd.Series('blue', elec_list)\n",
    "h2_pipe_list = pd.Series('green', h2_pipe_list)\n",
    "line_colors = pd.Series('white', network.lines.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35404383",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "link_colors = elec_list.append(h2_pipe_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd809c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "link_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412719da",
   "metadata": {},
   "outputs": [],
   "source": [
    "fnb_2030_plus = [['Eichstetten_110kV', 'Lorrach_110kV'],\n",
    "                ['KarlsruheWest_110kV', 'HeidelburgSud_110kV'],\n",
    "                ['HeidelburgSud_110kV', 'Grossgartach_110kV'],\n",
    "                ['Grossgartach_110kV', 'Kupferzell_110kV'],\n",
    "                ['Sindelfingen_110kV', 'Birkenfeld_110kV'],\n",
    "                ['Sindelfingen_110kV', 'Oberjettingen_110kV'],\n",
    "                ['Reutlingen_110kV', 'Laufen_an_der_Eyach_110kV'],\n",
    "                ['Sipplingen_110kV', 'Markdorf_110kV'],\n",
    "                ['Biberach_110kV', 'Ravensburg_110kV'],\n",
    "                ['Goldshofe_110kV', 'Giengen_110kV']]\n",
    "\n",
    "if h2_pipe_config == 'short_fnb_2030':\n",
    "    \n",
    "    for i_count in range(len(fnb_2030_plus)):\n",
    "        link_colors.loc['{}_{}_h2_pipe'.format(fnb_2030_plus[i_count][0], fnb_2030_plus[i_count][1])] = 'red'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a099eda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "link_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f002ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "map = folium.Map(location=[48.77000, 9.18], zoom_start=7, tiles=\"OpenStreetMap\")\n",
    "\n",
    "#tooltip = \"Click me!\"\n",
    "\n",
    "# y # x\n",
    "\n",
    "for x in range(len(df_h2_buses_load)):\n",
    "    folium.Marker([df_h2_buses_load['y'][x], df_h2_buses_load['x'][x]], \n",
    "            popup=\"<i>{}_H2_bus</i>\".format(df_h2_buses_load.index[x])).add_to(map)\n",
    "\n",
    "map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c05ffb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(\n",
    "    1, 1, subplot_kw={\"projection\": ccrs.EqualEarth()}, figsize=(10, 10)\n",
    ")\n",
    "\n",
    "network.plot(ax=ax, margin=0.08, bus_sizes = 0.0005, color_geomap=True, \n",
    "             link_colors = link_colors, line_colors = line_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed92cda",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "network.lopf(pyomo=False, solver_name='gurobi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816974cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "network.generators.p_nom_opt.plot.bar(ylabel='MW', figsize=(15,10))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870942d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_carr = list(network.carriers.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614eca32",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_carr = list(np.unique(list(network.generators.carrier)))\n",
    "gen_carr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b6f0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen_p_nom_opt = pd.DataFrame(index=gen_carr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f9cd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_p_nom_opt_list = []\n",
    "gen_p_nom_list = []\n",
    "\n",
    "for carr_count_x in range(len(gen_carr)):\n",
    "    p_nom_opt_sum_x = network.generators[network.generators['carrier'] == '{}'.format(gen_carr[carr_count_x])]['p_nom_opt'].sum()\n",
    "    p_nom_sum_x = network.generators[network.generators['carrier'] == '{}'.format(gen_carr[carr_count_x])]['p_nom'].sum()\n",
    "    gen_p_nom_opt_list.append(round(p_nom_opt_sum_x,2))\n",
    "    gen_p_nom_list.append(round(p_nom_sum_x,2))\n",
    "    \n",
    "\n",
    "df_gen_p_nom_opt['capacity p_nom_sum (MW)'] = gen_p_nom_list\n",
    "df_gen_p_nom_opt['p_nom_opt_sum (MW)'] = gen_p_nom_opt_list  \n",
    "\n",
    "df_gen_p_nom_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74d367b",
   "metadata": {},
   "outputs": [],
   "source": [
    "network.generators.p_nom_opt.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadd3c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "su_unit_carr = list(np.unique(list(network.storage_units.carrier)))\n",
    "su_unit_carr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2faeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stor_unit_p_nom_opt = pd.DataFrame(index=su_unit_carr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a816011",
   "metadata": {},
   "outputs": [],
   "source": [
    "su_p_nom_opt_list = []\n",
    "su_p_nom_list = []\n",
    "\n",
    "for carr_count_y in range(len(su_unit_carr)):\n",
    "    p_nom_opt_sum_y = network.storage_units[network.storage_units['carrier'] == '{}'.format(su_unit_carr[carr_count_y])]['p_nom_opt'].sum()\n",
    "    p_nom_sum_y = network.storage_units[network.storage_units['carrier'] == '{}'.format(su_unit_carr[carr_count_y])]['p_nom'].sum()\n",
    "    su_p_nom_opt_list.append(round(p_nom_opt_sum_y,2))\n",
    "    su_p_nom_list.append(round(p_nom_sum_y,2))\n",
    "    \n",
    "\n",
    "df_stor_unit_p_nom_opt['capacity p_nom_sum (MW)'] = su_p_nom_list\n",
    "df_stor_unit_p_nom_opt['p_nom_opt_sum (MW)'] = su_p_nom_opt_list  \n",
    "\n",
    "df_stor_unit_p_nom_opt        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0f0eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "network.links.p_nom_opt.plot.bar(ylabel='MW', figsize=(15,10))\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
