{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce5c61c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import folium\n",
    "import pandas as pd\n",
    "import pypsa\n",
    "from geopy import distance\n",
    "from geopy.geocoders import Nominatim\n",
    "from time import sleep\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f79feb0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_network(years_select):\n",
    "    # calls get_electrical_data to get string of the folder name containing the pypsa network csv files\n",
    "    # imports pypsa network csv files\n",
    "    # returns pypsa network to Case 1 / Case 2 / Case 3 script\n",
    "\n",
    "    years_simulate = years_select\n",
    "    network = pypsa.Network(get_electrical_data(years_simulate))\n",
    "\n",
    "    return network\n",
    "\n",
    "\n",
    "def get_electrical_data(years_elect):\n",
    "    # returns string of the folder name containing the pypsa network csv files: buses, generators, storage_units & etc.\n",
    "\n",
    "    if years_elect == '2030':\n",
    "        return \"C:/Users/work/pypsa_thesis/data/electrical/2030\"\n",
    "    elif years_elect == '2040':\n",
    "        return \"C:/Users/work/pypsa_thesis/data/electrical/2040\"\n",
    "    elif years_elect == '2050':\n",
    "        return \"C:/Users/work/pypsa_thesis/data/electrical/2050\"\n",
    "\n",
    "\n",
    "def calculate_annuity(n, r):\n",
    "    # calculate the annuity factor for an asset with lifetime n years and\n",
    "    # discount rate of r, e.g. annuity(20, 0.05) * 20 = 1.6\n",
    "    # source: pypsa-eur add_electricity script\n",
    "    # returns calculated annuity factor for the capital costs' calculation in get_techno_econ_data function\n",
    "\n",
    "    if isinstance(r, pd.Series):\n",
    "        return pd.Series(1 / n, index=r.index).where(r == 0, r / (1. - 1. / (1. + r) ** n))\n",
    "    elif r > 0:\n",
    "        return r / (1. - 1. / (1. + r) ** n)\n",
    "    else:\n",
    "        return 1 / n\n",
    "\n",
    "\n",
    "def get_techno_econ_data(n_years, years_data, discount_rate, network):\n",
    "    # calculates capital costs, marginal costs for generators, storage units, electrolysis, H2 pipelines\n",
    "    # assign values for co2 emissions, efficiency\n",
    "    # returns dataframe consist of above mentioned data\n",
    "\n",
    "    network = network\n",
    "    discount_rate = discount_rate\n",
    "    n_years = n_years\n",
    "\n",
    "    # loads techno economic parameters for different technologies based on pypsa technology-data repository\n",
    "    if years_data == '2030':\n",
    "        load_data = pd.read_csv(\"C:/Users/work/pypsa_thesis/data/techno_economic/pypsa_costs_2030.csv\")\n",
    "        df_load_data = pd.DataFrame(load_data)\n",
    "    elif years_data == '2040':\n",
    "        load_data = pd.read_csv(\"C:/Users/work/pypsa_thesis/data/techno_economic/pypsa_costs_2040.csv\")\n",
    "        df_load_data = pd.DataFrame(load_data)\n",
    "    elif years_data == '2050':\n",
    "        load_data = pd.read_csv(\"C:/Users/work/pypsa_thesis/data/techno_economic/pypsa_costs_2050.csv\")\n",
    "        df_load_data = pd.DataFrame(load_data)\n",
    "\n",
    "    # correct units to MW\n",
    "    df_load_data.loc[df_load_data.unit.str.contains(\"/kW\"), \"value\"] *= 1e3\n",
    "\n",
    "    # creates df which stores capital costs, marginal costs, efficiency and co2 emissions for generators, storage units,\n",
    "    # electrolysis and H2 pipelines based on their 'carriers' names\n",
    "    df_tech_costs = pd.DataFrame(columns=['carriers', 'capital_costs', 'marginal_costs',\n",
    "                                          'efficiency', 'efficiency_store',\n",
    "                                          'efficiency_dispatch', 'co2_emissions'])\n",
    "    df_tech_costs['carriers'] = list(network.carriers.index)\n",
    "    df_tech_costs.set_index('carriers', inplace=True)\n",
    "\n",
    "    # calculation of capital costs for different generation technologies\n",
    "    # inspired from pypsa-eur add_electricity script\n",
    "    # assign efficiency for different generation technologies\n",
    "    for carrier_x in list(df_tech_costs.index):\n",
    "        if carrier_x != 'H2' or carrier_x != 'Water_Reservoir':\n",
    "            if carrier_x in list(df_load_data['technology']):\n",
    "                if carrier_x == 'Pumped_Storage':\n",
    "                    df_cap_cost = pd.DataFrame(df_load_data[df_load_data['technology'] == carrier_x])\n",
    "                    lifetime = float(df_cap_cost[df_cap_cost['parameter'] == 'lifetime']['value'])\n",
    "                    FOM = float(df_cap_cost[df_cap_cost['parameter'] == 'FOM']['value'])\n",
    "                    investment = float(df_cap_cost[df_cap_cost['parameter'] == 'investment']['value'])\n",
    "                    efficiency_x = float(df_cap_cost[df_cap_cost['parameter'] == 'efficiency']['value'])\n",
    "                    df_tech_costs.at[carrier_x, 'capital_costs'] = round(((calculate_annuity(lifetime, discount_rate) +\n",
    "                                                                           FOM / 100.) *\n",
    "                                                                          investment * n_years), 2)\n",
    "                    df_tech_costs.at[carrier_x, 'efficiency_store'] = round(np.sqrt(efficiency_x), 2)\n",
    "                    df_tech_costs.at[carrier_x, 'efficiency_dispatch'] = round(np.sqrt(efficiency_x), 2)\n",
    "\n",
    "                elif carrier_x not in ('Solar', 'Wind_Offshore', 'Wind_Onshore', 'H2_(g)_pipeline'):\n",
    "                    df_cap_cost = pd.DataFrame(df_load_data[df_load_data['technology'] == carrier_x])\n",
    "                    lifetime = float(df_cap_cost[df_cap_cost['parameter'] == 'lifetime']['value'])\n",
    "                    FOM = float(df_cap_cost[df_cap_cost['parameter'] == 'FOM']['value'])\n",
    "                    investment = float(df_cap_cost[df_cap_cost['parameter'] == 'investment']['value'])\n",
    "                    efficiency_x = float(df_cap_cost[df_cap_cost['parameter'] == 'efficiency']['value'])\n",
    "                    df_tech_costs.at[carrier_x, 'capital_costs'] = round(((calculate_annuity(lifetime, discount_rate) +\n",
    "                                                                           FOM / 100.) *\n",
    "                                                                          investment * n_years), 2)\n",
    "                    df_tech_costs.at[carrier_x, 'efficiency'] = efficiency_x\n",
    "\n",
    "                else:\n",
    "                    df_cap_cost = pd.DataFrame(df_load_data[df_load_data['technology'] == carrier_x])\n",
    "                    lifetime = float(df_cap_cost[df_cap_cost['parameter'] == 'lifetime']['value'])\n",
    "                    FOM = float(df_cap_cost[df_cap_cost['parameter'] == 'FOM']['value'])\n",
    "                    investment = float(df_cap_cost[df_cap_cost['parameter'] == 'investment']['value'])\n",
    "                    df_tech_costs.at[carrier_x, 'capital_costs'] = round(((calculate_annuity(lifetime, discount_rate) +\n",
    "                                                                           FOM / 100.) *\n",
    "                                                                          investment * n_years), 2)\n",
    "                    df_tech_costs.at[carrier_x, 'efficiency'] = 1.0\n",
    "\n",
    "    # calculation of marginal costs for different generation technologies\n",
    "    # inspired from pypsa-eur add_electricity script\n",
    "    # assign efficiency for different generation technologies\n",
    "    for carrier_y in list(df_tech_costs.index):\n",
    "        if carrier_y in ('Biomass', 'CCGT', 'Coal', 'Lignite', 'Oil'):\n",
    "            if carrier_y == 'CCGT':\n",
    "                df_mar_cost = pd.DataFrame(df_load_data[df_load_data['technology'] == carrier_y])\n",
    "                VOM = float(df_mar_cost[df_mar_cost['parameter'] == 'VOM']['value'])\n",
    "                fuel = float(\n",
    "                    df_load_data[(df_load_data['parameter'] == 'fuel') & (df_load_data['technology'] == 'gas')][\n",
    "                        'value'])\n",
    "                efficiency_y = float(df_mar_cost[df_mar_cost['parameter'] == 'efficiency']['value'])\n",
    "                df_tech_costs.at[carrier_y, 'marginal_costs'] = round(VOM + fuel / efficiency_y, 2)\n",
    "            elif carrier_y == 'Biomass':\n",
    "                fuel = float(\n",
    "                    df_load_data[(df_load_data['parameter'] == 'fuel') & (df_load_data['technology'] == carrier_y)][\n",
    "                        'value'])\n",
    "                efficiency_y = float(df_load_data[(df_load_data['parameter'] == 'efficiency') & (\n",
    "                        df_load_data['technology'] == carrier_y)]['value'])\n",
    "                df_tech_costs.at[carrier_y, 'marginal_costs'] = round(fuel / efficiency_y, 2)\n",
    "            else:\n",
    "                df_mar_cost = pd.DataFrame(df_load_data[df_load_data['technology'] == carrier_y])\n",
    "                VOM = float(df_mar_cost[df_mar_cost['parameter'] == 'VOM']['value'])\n",
    "                fuel = float(df_mar_cost[df_mar_cost['parameter'] == 'fuel']['value'])\n",
    "                efficiency_y = float(df_mar_cost[df_mar_cost['parameter'] == 'efficiency']['value'])\n",
    "                df_tech_costs.at[carrier_y, 'marginal_costs'] = round(VOM + fuel / efficiency_y, 2)\n",
    "\n",
    "    # assign co2 emissions values for different generation technologies\n",
    "    for carrier_z in list(df_tech_costs.index):\n",
    "        if carrier_z in ('OCGT', 'CCGT', 'Coal', 'Lignite', 'Oil'):\n",
    "            if carrier_z == 'OCGT' or carrier_z == 'CCGT':\n",
    "                co2_intensity = float(df_load_data[(df_load_data['technology'] == 'Gas') &\n",
    "                                                   (df_load_data['parameter'] == 'CO2 intensity')]['value'])\n",
    "                df_tech_costs.at['{}'.format(carrier_z), 'co2_emissions'] = co2_intensity\n",
    "            else:\n",
    "                co2_intensity = float(df_load_data[(df_load_data['technology'] == '{}'.format(carrier_z)) &\n",
    "                                                   (df_load_data['parameter'] == 'CO2 intensity')]['value'])\n",
    "                df_tech_costs.at['{}'.format(carrier_z), 'co2_emissions'] = co2_intensity\n",
    "\n",
    "    df_tech_costs.fillna(0, inplace=True)\n",
    "\n",
    "    for x_carrier in list(df_tech_costs.index):\n",
    "        for y_carrier, y_loc in zip(list(network.generators['carrier']), list(network.generators.index)):\n",
    "            if x_carrier == y_carrier:\n",
    "                cap_cost_x = df_tech_costs.at['{}'.format(x_carrier), 'capital_costs']\n",
    "                mar_cost_x = df_tech_costs.at['{}'.format(x_carrier), 'marginal_costs']\n",
    "                gen_efficiency_x = df_tech_costs.at['{}'.format(x_carrier), 'efficiency']\n",
    "                network.generators.at['{}'.format(y_loc), 'capital_cost'] = cap_cost_x\n",
    "                network.generators.at['{}'.format(y_loc), 'marginal_cost'] = mar_cost_x\n",
    "                network.generators.at['{}'.format(y_loc), 'efficiency'] = gen_efficiency_x\n",
    "\n",
    "    # capital costs, marginal costs, efficiency for storage units\n",
    "    for p_carrier in list(df_tech_costs.index):\n",
    "        for q_carrier, q_loc in zip(list(network.storage_units['carrier']), list(network.storage_units.index)):\n",
    "            if p_carrier == q_carrier:\n",
    "                cap_cost_p = df_tech_costs.at['{}'.format(p_carrier), 'capital_costs']\n",
    "                mar_cost_p = df_tech_costs.at['{}'.format(p_carrier), 'marginal_costs']\n",
    "                efficiency_store = df_tech_costs.at['{}'.format(p_carrier), 'efficiency_store']\n",
    "                efficiency_dispatch = df_tech_costs.at['{}'.format(p_carrier), 'efficiency_dispatch']\n",
    "                network.storage_units.at['{}'.format(q_loc), 'capital_cost'] = cap_cost_p\n",
    "                network.storage_units.at['{}'.format(q_loc), 'marginal_cost'] = mar_cost_p\n",
    "                network.storage_units.at['{}'.format(q_loc), 'efficiency_store'] = efficiency_store\n",
    "                network.storage_units.at['{}'.format(q_loc), 'efficiency_dispatch'] = efficiency_dispatch\n",
    "\n",
    "    # co2 emissions for each carriers\n",
    "    for r_carrier in list(df_tech_costs.index):\n",
    "        for s_carrier in list(network.carriers.index):\n",
    "            if r_carrier == s_carrier:\n",
    "                co2_emi = df_tech_costs.at['{}'.format(r_carrier), 'co2_emissions']\n",
    "                network.carriers.at['{}'.format(s_carrier), 'co2_emissions'] = co2_emi\n",
    "\n",
    "    return df_tech_costs\n",
    "\n",
    "\n",
    "def get_hydrogen_data(scenario_h2, years_h2, h2_config, network):\n",
    "    # loads raw H2 demand data from Fraunhofer\n",
    "\n",
    "    network = network\n",
    "    if scenario_h2 == 'TN-H2-G':\n",
    "        if years_h2 == '2030':\n",
    "            load_data = pd.read_csv(\"C:/Users/work/pypsa_thesis/data/hydrogen/TN-H2-G/BW_2030.csv\",\n",
    "                                    index_col=0)\n",
    "\n",
    "        elif years_h2 == '2040':\n",
    "            load_data = pd.read_csv(\"C:/Users/work/pypsa_thesis/data/hydrogen/TN-H2-G/BW_2040.csv\",\n",
    "                                    index_col=0)\n",
    "\n",
    "        elif years_h2 == '2050':\n",
    "            load_data = pd.read_csv(\"C:/Users/work/pypsa_thesis/data/hydrogen/TN-H2-G/BW_2050.csv\",\n",
    "                                    index_col=0)\n",
    "\n",
    "    elif scenario_h2 == 'TN-PtG-PtL':\n",
    "        if years_h2 == '2030':\n",
    "            load_data = pd.read_csv(\"C:/Users/work/pypsa_thesis/data/hydrogen/TN-PtG-PtL/BW_2030.csv\",\n",
    "                                    index_col=0)\n",
    "\n",
    "        elif years_h2 == '2040':\n",
    "            load_data = pd.read_csv(\"C:/Users/work/pypsa_thesis/data/hydrogen/TN-PtG-PtL/BW_2040.csv\",\n",
    "                                    index_col=0)\n",
    "\n",
    "        elif years_h2 == '2050':\n",
    "            load_data = pd.read_csv(\"C:/Users/work/pypsa_thesis/data/hydrogen/TN-PtG-PtL/BW_2050.csv\",\n",
    "                                    index_col=0)\n",
    "\n",
    "    elif scenario_h2 == 'TN-Strom':\n",
    "        if years_h2 == '2030':\n",
    "            load_data = pd.read_csv(\"C:/Users/work/pypsa_thesis/data/hydrogen/TN-Strom/BW_2030.csv\",\n",
    "                                    index_col=0)\n",
    "\n",
    "        elif years_h2 == '2040':\n",
    "            load_data = pd.read_csv(\"C:/Users/work/pypsa_thesis/data/hydrogen/TN-Strom/BW_2040.csv\",\n",
    "                                    index_col=0)\n",
    "\n",
    "        elif years_h2 == '2050':\n",
    "            load_data = pd.read_csv(\"C:/Users/work/pypsa_thesis/data/hydrogen/TN-Strom/BW_2050.csv\",\n",
    "                                    index_col=0)\n",
    "\n",
    "    df_h2_demand = pd.DataFrame(load_data)\n",
    "    df_h2_demand.index.names = ['location_name']\n",
    "    df_h2_demand.reset_index(inplace=True)\n",
    "    df_h2_demand.dropna(subset=['location_name'], inplace=True)\n",
    "    df_h2_demand['demand_value'] = df_h2_demand['demand_value'].div(8760)  # from TWh/a to TW\n",
    "    df_h2_demand['demand_value'] = df_h2_demand['demand_value'].multiply(1e6)  # from TW to MW\n",
    "    x_coor = []\n",
    "    y_coor = []\n",
    "\n",
    "    for loc_count in range(len(df_h2_demand['location_name'])):\n",
    "        geolocator = Nominatim(user_agent=\"locate_h2_demand\")\n",
    "        locate_h2_demand = geolocator.geocode(df_h2_demand['location_name'][loc_count].split(',')[0],\n",
    "                                              timeout=None)\n",
    "        x_coor.append(locate_h2_demand.longitude)\n",
    "        y_coor.append(locate_h2_demand.latitude)\n",
    "        sleep(1)\n",
    "\n",
    "    df_h2_demand['x'] = x_coor\n",
    "    df_h2_demand['y'] = y_coor\n",
    "    df_ac_loads_h2_loads_dist = pd.DataFrame(index=network.loads.index, columns=df_h2_demand['location_name'])\n",
    "\n",
    "    for city_count_x in range(len(network.loads.index)):\n",
    "        for city_count_y in range(len(df_h2_demand['location_name'])):\n",
    "            if network.loads.index[city_count_x] != df_h2_demand['location_name'][city_count_y]:\n",
    "                city_1 = (network.loads['y'][city_count_x], network.loads['x'][city_count_x])\n",
    "                city_2 = (df_h2_demand['y'][city_count_y], df_h2_demand['x'][city_count_y])\n",
    "                dist_city1_city2 = distance.distance(city_1, city_2).km\n",
    "                df_ac_loads_h2_loads_dist.at[\n",
    "                    network.loads.index[city_count_x], df_h2_demand['location_name'][city_count_y]] = dist_city1_city2\n",
    "\n",
    "    ac_loads_h2_links = []\n",
    "\n",
    "    for column_count_x in df_ac_loads_h2_loads_dist.columns:\n",
    "        for distance_count_x in range(len(df_ac_loads_h2_loads_dist[column_count_x])):\n",
    "            if df_ac_loads_h2_loads_dist[column_count_x][distance_count_x] == \\\n",
    "                    df_ac_loads_h2_loads_dist[column_count_x].min():\n",
    "                ac_loads_h2_links.append(df_ac_loads_h2_loads_dist.index[distance_count_x])\n",
    "\n",
    "    ac_loads_h2_links = list(dict.fromkeys(ac_loads_h2_links))\n",
    "\n",
    "    df_h2_buses_load = pd.DataFrame(index=ac_loads_h2_links, columns={'h2_load': [], 'x': [], 'y': []})\n",
    "\n",
    "    for buses_count in range(len(network.buses.index)):\n",
    "        for h2_buses_count in range(len(df_h2_buses_load.index)):\n",
    "            if network.buses.index[buses_count] == df_h2_buses_load.index[h2_buses_count]:\n",
    "                df_h2_buses_load['x'][h2_buses_count] = network.buses['x'][buses_count]\n",
    "                df_h2_buses_load['y'][h2_buses_count] = network.buses['y'][buses_count]\n",
    "\n",
    "    df_h2_buses_load.fillna(0, inplace=True)\n",
    "\n",
    "    for column_count_y, i_count_y in zip(df_ac_loads_h2_loads_dist.columns, range(len(df_h2_demand['location_name']))):\n",
    "        for distance_count_y in range(len(df_ac_loads_h2_loads_dist[column_count_y])):\n",
    "            if df_ac_loads_h2_loads_dist[column_count_y][distance_count_y] == \\\n",
    "                    df_ac_loads_h2_loads_dist[column_count_y].min():\n",
    "                h2_load_value = df_h2_demand[df_h2_demand['location_name'] == column_count_y]['demand_value'][\n",
    "                    i_count_y]\n",
    "                h2_demand_loc = df_ac_loads_h2_loads_dist.index[distance_count_y]\n",
    "                if df_h2_buses_load.at[h2_demand_loc, 'h2_load'] == 0:\n",
    "                    df_h2_buses_load.at[h2_demand_loc, 'h2_load'] = h2_load_value\n",
    "                else:\n",
    "                    df_h2_buses_load.at[h2_demand_loc, 'h2_load'] = df_h2_buses_load.at[h2_demand_loc, 'h2_load'] + \\\n",
    "                                                                    h2_load_value\n",
    "\n",
    "    df_h2_pipelines_dist = pd.DataFrame(index=ac_loads_h2_links, columns=ac_loads_h2_links)\n",
    "\n",
    "    for column_count_z in range(len(list(df_h2_pipelines_dist.index))):\n",
    "        for row_count_z in range(len(list(df_h2_pipelines_dist.columns))):\n",
    "            if df_h2_pipelines_dist.index[column_count_z] != df_h2_pipelines_dist.columns[row_count_z]:\n",
    "                loc_1 = (df_h2_buses_load['y'][column_count_z], df_h2_buses_load['x'][column_count_z])\n",
    "                loc_2 = (df_h2_buses_load['y'][row_count_z], df_h2_buses_load['x'][row_count_z])\n",
    "                dist_loc_1_loc_2 = distance.distance(loc_1, loc_2).km\n",
    "                df_h2_pipelines_dist.at[\n",
    "                    df_h2_pipelines_dist.columns[row_count_z], df_h2_pipelines_dist.index[column_count_z]] = \\\n",
    "                    dist_loc_1_loc_2\n",
    "\n",
    "    if h2_config == 'short':\n",
    "\n",
    "        h2_pipe_row_list = []\n",
    "        h2_bus_0_list = []\n",
    "        h2_bus_1_list = []\n",
    "        bus_0_list = []\n",
    "        bus_1_list = []\n",
    "        distance_km_list = []\n",
    "\n",
    "        for city_count_p in list(df_h2_pipelines_dist.columns):\n",
    "            for city_count_q in range(len(list(df_h2_pipelines_dist.index))):\n",
    "                if df_h2_pipelines_dist[city_count_p][city_count_q] == \\\n",
    "                        df_h2_pipelines_dist[city_count_p].min():\n",
    "                    h2_pipe_row_list.append(\n",
    "                        '{}_{}_h2_pipe'.format(city_count_p, df_h2_pipelines_dist.index[city_count_q]))\n",
    "                    h2_bus_0_list.append('{}_H2_Bus'.format(city_count_p))\n",
    "                    h2_bus_1_list.append('{}_H2_Bus'.format(df_h2_pipelines_dist.index[city_count_q]))\n",
    "                    bus_0_list.append(city_count_p)\n",
    "                    bus_1_list.append(df_h2_pipelines_dist.index[city_count_q])\n",
    "                    distance_km_list.append(df_h2_pipelines_dist[city_count_p].min())\n",
    "\n",
    "        df_h2_pipelines = pd.DataFrame(index=h2_pipe_row_list)\n",
    "        df_h2_pipelines.index.names = ['H2_pipelines']\n",
    "\n",
    "        df_h2_pipelines['bus_0'] = h2_bus_0_list\n",
    "        df_h2_pipelines['bus_1'] = h2_bus_1_list\n",
    "        df_h2_pipelines['distance_km'] = distance_km_list\n",
    "\n",
    "        df_h2_pipelines.drop_duplicates(subset=['distance_km'], inplace=True)\n",
    "\n",
    "    elif h2_config == 'all':\n",
    "\n",
    "        h2_pipe_row_list = []\n",
    "        h2_bus_0_list = []\n",
    "        h2_bus_1_list = []\n",
    "        bus_0_list = []\n",
    "        bus_1_list = []\n",
    "        distance_km_list = []\n",
    "\n",
    "        for city_count_r in list(df_h2_pipelines_dist.columns):\n",
    "            for city_count_s, i_count_s in zip(list(df_h2_pipelines_dist.index),\n",
    "                                               range(len(list(df_h2_pipelines_dist.index)))):\n",
    "                if city_count_r != city_count_s:\n",
    "                    h2_pipe_row_list.append(\n",
    "                        '{}_{}_h2_pipe'.format(city_count_r, city_count_s))\n",
    "                    h2_bus_0_list.append('{}_H2_Bus'.format(city_count_r))\n",
    "                    h2_bus_1_list.append('{}_H2_Bus'.format(city_count_s))\n",
    "                    bus_0_list.append(city_count_r)\n",
    "                    bus_1_list.append(city_count_s)\n",
    "                    distance_km_list.append(df_h2_pipelines_dist[city_count_r][i_count_s])\n",
    "\n",
    "        df_h2_pipelines = pd.DataFrame(index=h2_pipe_row_list)\n",
    "        df_h2_pipelines.index.names = ['H2_pipelines']\n",
    "\n",
    "        df_h2_pipelines['bus_0'] = h2_bus_0_list\n",
    "        df_h2_pipelines['bus_1'] = h2_bus_1_list\n",
    "        df_h2_pipelines['distance_km'] = distance_km_list\n",
    "\n",
    "        df_h2_pipelines.drop_duplicates(subset=['distance_km'], inplace=True)\n",
    "\n",
    "    elif h2_config == 'short_fnb_2030':\n",
    "\n",
    "        h2_pipe_row_list = []\n",
    "        h2_bus_0_list = []\n",
    "        h2_bus_1_list = []\n",
    "        bus_0_list = []\n",
    "        bus_1_list = []\n",
    "        distance_km_list = []\n",
    "\n",
    "        for city_count_a in list(df_h2_pipelines_dist.columns):\n",
    "            for city_count_b in range(len(list(df_h2_pipelines_dist.index))):\n",
    "                if df_h2_pipelines_dist[city_count_a][city_count_b] == \\\n",
    "                        df_h2_pipelines_dist[city_count_a].min():\n",
    "                    h2_pipe_row_list.append(\n",
    "                        '{}_{}_h2_pipe'.format(city_count_a, df_h2_pipelines_dist.index[city_count_b]))\n",
    "                    h2_bus_0_list.append('{}_H2_Bus'.format(city_count_a))\n",
    "                    h2_bus_1_list.append('{}_H2_Bus'.format(df_h2_pipelines_dist.index[city_count_b]))\n",
    "                    bus_0_list.append(city_count_a)\n",
    "                    bus_1_list.append(df_h2_pipelines_dist.index[city_count_b])\n",
    "                    distance_km_list.append(df_h2_pipelines_dist[city_count_a].min())\n",
    "\n",
    "        # after connecting the H2 pipelines based on shortest distance between the H2 buses\n",
    "        # limitation #3: the remaining end points are connected MANUALLY roughly based on proposed FNB H2 network\n",
    "        # below connections currently only for BW\n",
    "\n",
    "        if scenario_h2 == 'TN-H2-G':\n",
    "            fnb_2030_add = [['Eichstetten_110kV', 'Lorrach_110kV'],\n",
    "                            ['KarlsruheWest_110kV', 'HeidelburgSud_110kV'],\n",
    "                            ['Grossgartach_110kV', 'Kupferzell_110kV'],\n",
    "                            ['Sindelfingen_110kV', 'Birkenfeld_110kV'],\n",
    "                            ['Sindelfingen_110kV', 'Oberjettingen_110kV'],\n",
    "                            ['Sipplingen_110kV', 'Markdorf_110kV'],\n",
    "                            ['Biberach_110kV', 'Ravensburg_110kV'],\n",
    "                            ['Goldshofe_110kV', 'Giengen_110kV']]\n",
    "\n",
    "        elif scenario_h2 == 'TN-PtG-PtL':\n",
    "            fnb_2030_add = [['KarlsruheWest_110kV', 'GKMannheim_110kV'],\n",
    "                            ['KarlsruheWest_110kV', 'Sindelfingen_110kV'],\n",
    "                            ['Sipplingen_110kV', 'Schmiechen_110kV'],\n",
    "                            ['Pfahlbronn_110kV', 'Giengen_110kV']]\n",
    "\n",
    "        elif scenario_h2 == 'TN-Strom':\n",
    "            fnb_2030_add = [['Kuppenheim_110kV', 'Lorrach_110kV'],\n",
    "                            ['KarlsruheWest_110kV', 'GKMannheim_110kV'],\n",
    "                            ['KarlsruheWest_110kV', 'Stuttgart_110kV'],\n",
    "                            ['Schmiechen_110kV', 'Laufen_an_der_Eyach_110kV'],\n",
    "                            ['Pfahlbronn_110kV', 'Giengen_110kV']]\n",
    "\n",
    "        for city_add in range(len(fnb_2030_add)):\n",
    "            h2_pipe_row_list.append('{}_{}_h2_pipe'.format(fnb_2030_add[city_add][0], fnb_2030_add[city_add][1]))\n",
    "            h2_bus_0_list.append('{}_H2_Bus'.format(fnb_2030_add[city_add][0]))\n",
    "            h2_bus_1_list.append('{}_H2_Bus'.format(fnb_2030_add[city_add][1]))\n",
    "            bus_0_list.append(fnb_2030_add[city_add][0])\n",
    "            distance_km_list.append(df_h2_pipelines_dist.at[fnb_2030_add[city_add][0], fnb_2030_add[city_add][1]])\n",
    "\n",
    "        df_h2_pipelines = pd.DataFrame(index=h2_pipe_row_list)\n",
    "        df_h2_pipelines.index.names = ['H2_pipelines']\n",
    "\n",
    "        df_h2_pipelines['bus_0'] = h2_bus_0_list\n",
    "        df_h2_pipelines['bus_1'] = h2_bus_1_list\n",
    "        df_h2_pipelines['distance_km'] = distance_km_list\n",
    "\n",
    "        df_h2_pipelines.drop_duplicates(subset=['distance_km'], inplace=True)\n",
    "\n",
    "    all_bus_list = bus_0_list + bus_1_list\n",
    "    connected_list = []\n",
    "\n",
    "    for city_check in ac_loads_h2_links:\n",
    "        if city_check not in all_bus_list:\n",
    "            print('{} not connected to any bus'.format(city_check))\n",
    "        else:\n",
    "            connected_list.append('{} is connected to a H2 bus'.format(city_check))\n",
    "\n",
    "    dict_h2_data = {'h2_links': ac_loads_h2_links,\n",
    "                    'h2_dataframe': df_h2_demand,\n",
    "                    'h2_buses_load': df_h2_buses_load,\n",
    "                    'h2_pipelines': df_h2_pipelines,\n",
    "                    'h2_demand_value_total': round(sum(df_h2_demand['demand_value']) * 1e6, 2)}  # in MWh\n",
    "\n",
    "    return dict_h2_data\n",
    "\n",
    "\n",
    "def set_re_profile(network):\n",
    "    # gets profile for solar, wind, and hydro run-of-river\n",
    "    # currently customized only for snapshots 365 days, 24H freq\n",
    "    # notes on 28.08.2022\n",
    "    network = network\n",
    "\n",
    "    pmaxpu_generators = network.generators[\n",
    "        (network.generators['carrier'] == 'Solar') |\n",
    "        (network.generators['carrier'] == 'Run_of_River') |\n",
    "        (network.generators['carrier'] == 'Wind_Offshore') |\n",
    "        (network.generators['carrier'] == 'Wind_Onshore')]\n",
    "\n",
    "    network.generators_t.p_max_pu = network.generators_t.p_max_pu.reindex(columns=pmaxpu_generators.index)\n",
    "\n",
    "    network.generators_t.p_max_pu.loc[:, pmaxpu_generators.index] = pd.DataFrame(index=network.snapshots,\n",
    "                                                                                 columns=pmaxpu_generators.index\n",
    "                                                                                 )\n",
    "\n",
    "    ac_data = pd.read_excel(\n",
    "        \"C:/Users/work/pypsa_thesis/data/electrical/ac_profile/ac_gen_20210101_20211231_transnetBW.xlsx\")\n",
    "    date_time_list = ac_data['Date'] + ' ' + ac_data['Time of day']\n",
    "    ac_data.insert(0, 'timestamp', date_time_list)\n",
    "    ac_data['timestamp'] = pd.to_datetime(ac_data['timestamp'])\n",
    "    ac_data.drop(['Date', 'Time of day'], axis=1, inplace=True)\n",
    "    ac_data = ac_data.set_index(pd.to_datetime(ac_data['timestamp']))\n",
    "    ac_data_daily = ac_data.resample('D').sum()\n",
    "\n",
    "    for col in list(ac_data_daily.columns):\n",
    "        ac_data_daily[col] = ac_data_daily[col].div(24)  # MWh to MW\n",
    "\n",
    "    for gen in list(network.generators_t.p_max_pu.columns):\n",
    "        if 'ROF' in gen.split('_'):\n",
    "            gen_profile = ac_data_daily['ROF'].div(pmaxpu_generators.at[gen, 'p_nom']).where(lambda df: df <= 1.,\n",
    "                                                                                             other=1.)\n",
    "            network.generators_t.p_max_pu[gen] = list(gen_profile)\n",
    "\n",
    "    solar_data = pd.read_excel(\"C:/Users/work/pypsa_thesis/data/electrical/wind_solar_profile/solar_profile_2019.xlsx\")\n",
    "    wind_data = pd.read_excel(\"C:/Users/work/pypsa_thesis/data/electrical/wind_solar_profile/wind_profile_2019.xlsx\")\n",
    "\n",
    "    solar_data.set_index('start', inplace=True)\n",
    "    solar_data_daily = solar_data.resample('D').sum().where(lambda df: df <= 1., other=1.)\n",
    "    solar_profile_daily = list(solar_data_daily['DE'])\n",
    "\n",
    "    wind_data.set_index('start', inplace=True)\n",
    "    wind_data_daily = wind_data.resample('D').sum().where(lambda df: df <= 1., other=1.)\n",
    "    wind_profile_daily = list(wind_data_daily['DE'])\n",
    "\n",
    "    for re_loc in list(network.generators_t.p_max_pu.columns):\n",
    "        if 'SOL' in re_loc.split('_'):\n",
    "            network.generators_t.p_max_pu[re_loc] = solar_profile_daily\n",
    "\n",
    "        elif 'WON' in re_loc.split('_'):\n",
    "            network.generators_t.p_max_pu[re_loc] = wind_profile_daily\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83df5fed",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Case - 3 ###\n",
    "'''\n",
    "user input for:\n",
    "1) years to simulate\n",
    "2) which h2 demand scenario\n",
    "3) freq resolution in 1 year simulation - e.g. timesteps of: 24h / 12h / 6h / 1h \n",
    "4) annual discount rate of capital costs calculation for generators, storage units, electrolysis and H2 pipelines\n",
    "5) which h2 pipeline connection configuration (applicable for Case 3 only)\n",
    "'''\n",
    "\n",
    "years = '2050'  # subset of {'2030', '2040', '2050'}\n",
    "h2_scenario_demand = 'TN-H2-G'  # subset of {'TN-H2-G', 'TN-PtG-PtL', 'TN-Strom'}\n",
    "freq = '24'\n",
    "discount_rate = 0.07\n",
    "\n",
    "'''\n",
    "choose configuration of H2 pipelines connection (applicable for Case 3 only):\n",
    "1) 'short' - buses which have H2 demand (which are H2 buses), will connect to any H2 buses in the shortest distance\n",
    "2) 'all' - each H2 buses will connect to all other H2 buses regardless of short/long distances\n",
    "3) 'short_fnb_2030' - connects using 'short' config first and then follows roughly similar to proposed H2 pipeline\n",
    "                      connection based on FNB gas network development plan 2020 - 2030. This configuration currently\n",
    "                      LIMITED ONLY for 'TN-H2-G' H2 scenario demand \n",
    "                    \n",
    "'''\n",
    "h2_pipe_config = 'short'\n",
    "\n",
    "### Case - 3 ###\n",
    "\n",
    "# get electrical network from network csv files; generators, storage_units, lines, loads & etc.\n",
    "# create snapshots based on chosen 'years' and timesteps 'freq' to simulate\n",
    "\n",
    "network = get_network(years)\n",
    "\n",
    "snapshots = pd.DatetimeIndex([])\n",
    "period = pd.date_range(start='{}-01-01 00:00'.format(years),\n",
    "                       freq='{}H'.format(freq),\n",
    "                       periods=8760 / float(freq))\n",
    "snapshots = snapshots.append(period)\n",
    "\n",
    "network.snapshots = pd.MultiIndex.from_arrays([snapshots.year, snapshots])\n",
    "\n",
    "Nyears = network.snapshot_weightings.objective.sum() / 8760\n",
    "\n",
    "'''\n",
    "\n",
    "Nyears value depends on the snapshot resolution freq variable\n",
    "Change of Nyears value will affect the calculation of capital cost based on pypsa-eur methodology from \n",
    "the add_electricity script\n",
    "\n",
    "Nyears = network.snapshot_weightings.objective.sum() / 8760\n",
    "Nyears\n",
    "\n",
    "costs[\"capital_cost\"] = ((annuity(costs[\"lifetime\"], costs[\"discount rate\"]) + \n",
    "                            costs[\"FOM\"]/100.) *\n",
    "                            costs[\"investment\"] * Nyears)\n",
    "\n",
    "'''\n",
    "# calls get_techno_econ_data function to calculate capital costs, marginal costs, efficiency for generators,\n",
    "# storage_units, electrolysis and H2 pipeline\n",
    "# the function depends on Nyears (changes with the input value of 'freq' timesteps), years, discount rate\n",
    "# append capital costs, marginal costs, efficiency and co2 emissions into network generators, storage_units and carriers\n",
    "# the function returns network\n",
    "\n",
    "techno_econ_data = get_techno_econ_data(Nyears, years, discount_rate, network)\n",
    "\n",
    "# generates p_max_pu values for renewable generators based on data from open-power-system data repository:\n",
    "# current p_max_pu snapshots only applicable for 365 days snapshots length (24H freq) - note on 26.06.2022\n",
    "# Solar, Wind Onshore and Wind Offshore\n",
    "\n",
    "set_re_profile(network)\n",
    "\n",
    "# calls get_hydrogen_data function to:\n",
    "# acquire H2 demand data based on chosen H2 scenario demand 'h2_scenario_demand' and 'years' to simulate\n",
    "# builds H2 pipeline configuration based on chosen H2 pipeline configuration 'h2_pipe_config\n",
    "\n",
    "h2_data = get_hydrogen_data(h2_scenario_demand, years, h2_pipe_config, network)\n",
    "\n",
    "# builds and connects H2 network with Electrical Buses/Nodes network\n",
    "\n",
    "df_h2_buses_load = pd.DataFrame(h2_data['h2_buses_load'])  # dataframe of H2 demand for each H2 Buses/Loads\n",
    "df_h2_pipes = pd.DataFrame(h2_data['h2_pipelines'])  # dataframe of H2 pipeline connections between H2 Buses\n",
    "\n",
    "# creates H2 Buses\n",
    "\n",
    "h2_buses_names = list(df_h2_buses_load.index)\n",
    "\n",
    "h2_buses = [x + '_H2_Bus' for x in h2_buses_names]\n",
    "\n",
    "network.madd('Bus',\n",
    "             h2_buses,\n",
    "             carrier='H2',\n",
    "             x=list(df_h2_buses_load['x']),\n",
    "             y=list(df_h2_buses_load['y'])\n",
    "             )\n",
    "\n",
    "# electrolysis capital cost and efficiency are based on DEA agency data and pypsa methodology calculations\n",
    "\n",
    "electrolysis_cap_cost = techno_econ_data.at['Electrolysis', 'capital_costs']\n",
    "electrolysis_efficiency = techno_econ_data.at['Electrolysis', 'efficiency']\n",
    "\n",
    "# electrolysis_cap_cost = 0\n",
    "# electrolysis_efficiency = 1\n",
    "\n",
    "h2_links = [s + '_Electrolysis' for s in h2_buses_names[0:19]]\n",
    "\n",
    "# minimum number of electrolyzer to achieve successful optimization = 19 \n",
    "# notes on 26.06.2022\n",
    "\n",
    "# connects Electrical Buses/Nodes with H2 Buses using Electrolysis Links\n",
    "\n",
    "network.madd('Link',\n",
    "             h2_links,\n",
    "             carrier='H2',\n",
    "             capital_cost=electrolysis_cap_cost,\n",
    "             p_nom_extendable=True,\n",
    "             bus0=h2_buses_names[0:19],\n",
    "             bus1=h2_buses[0:19],\n",
    "             efficiency=electrolysis_efficiency)\n",
    "\n",
    "h2_pipe_cap_cost = techno_econ_data.at['H2_(g)_pipeline', 'capital_costs']\n",
    "h2_pipe_efficiency = techno_econ_data.at['H2_(g)_pipeline', 'efficiency']\n",
    "\n",
    "# h2_pipe_cap_cost = 0\n",
    "# h2_pipe_efficiency = 1\n",
    "\n",
    "# attach and connect H2 pipelines between the H2 buses\n",
    "\n",
    "network.madd('Link',\n",
    "             df_h2_pipes.index,\n",
    "             bus0=list(df_h2_pipes['bus_0']),\n",
    "             bus1=list(df_h2_pipes['bus_1']),\n",
    "             p_min_pu=-1,\n",
    "             p_nom_extendable=True,\n",
    "             length=list(df_h2_pipes['distance_km']),\n",
    "             capital_cost=h2_pipe_cap_cost * df_h2_pipes['distance_km'],\n",
    "             #capital_cost=0.1,\n",
    "             efficiency=h2_pipe_efficiency,\n",
    "             carrier='H2')\n",
    "\n",
    "# attach H2 Stores to H2 Buses\n",
    "\n",
    "h2_stores = [y + '_H2_Store' for y in h2_buses_names]\n",
    "\n",
    "network.madd('Store',\n",
    "             h2_stores,\n",
    "             bus=h2_buses,\n",
    "             carrier='H2',\n",
    "             e_nom_extendable=True)\n",
    "\n",
    "# attach H2 Loads to H2 Buses\n",
    "\n",
    "h2_loads = [z + '_H2_Load' for z in h2_buses_names]\n",
    "\n",
    "# time series AC and H2 load\n",
    "\n",
    "network.madd('Load',\n",
    "             h2_loads,\n",
    "             bus=h2_buses,\n",
    "             carrier='H2',\n",
    "             x=list(df_h2_buses_load['x']),\n",
    "             y=list(df_h2_buses_load['y'])\n",
    "             )\n",
    "\n",
    "# current limitation #1: generates random AC loads/demand for Electrical Buses/Nodes\n",
    "\n",
    "ac_loads = network.loads[(network.loads['carrier'] == 'AC')]\n",
    "\n",
    "ac_loads_p_set = pd.DataFrame(index=network.snapshots,\n",
    "                              columns=ac_loads.index,\n",
    "                              data=1000 * np.random.rand(len(network.snapshots), len(ac_loads)))\n",
    "\n",
    "# H2 loads set in series, based on Fraunhofer data\n",
    "\n",
    "df_h2_p_set = pd.DataFrame(index=network.snapshots, columns=h2_loads)\n",
    "\n",
    "for i_load in range(len(df_h2_p_set.columns)):\n",
    "    df_h2_p_set['{}'.format(df_h2_p_set.columns[i_load])] = df_h2_buses_load['h2_load'][i_load] / len(network.snapshots)\n",
    "\n",
    "# merge series of AC loads and H2 loads\n",
    "\n",
    "network.loads_t.p_set = pd.merge(ac_loads_p_set, df_h2_p_set, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb2adb7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# for electrolysis\n",
    "\n",
    "elec_list = []\n",
    "\n",
    "for y in network.links.index:\n",
    "    if '_Electrolysis' in y.split('110kV'):\n",
    "        elec_list.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbee3c0d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# for h2 pipes\n",
    "\n",
    "h2_pipe_list = []\n",
    "for x in network.links.index:\n",
    "    if '_h2_pipe' in x.split('110kV'):\n",
    "        h2_pipe_list.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a9fe93",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "elec_list = pd.Series('blue', elec_list)\n",
    "h2_pipe_list = pd.Series('green', h2_pipe_list)\n",
    "line_colors = pd.Series('white', network.lines.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35404383",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "link_colors = elec_list.append(h2_pipe_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd809c0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "link_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87953c92",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if h2_scenario_demand == 'TN-H2-G':\n",
    "    # below connections currently only for BW, only applicable for TN-H2-G scenario\n",
    "    fnb_2030_plus = [['Eichstetten_110kV', 'Lorrach_110kV'],\n",
    "                    ['KarlsruheWest_110kV', 'HeidelburgSud_110kV'],\n",
    "                    ['Grossgartach_110kV', 'Kupferzell_110kV'],\n",
    "                    ['Sindelfingen_110kV', 'Birkenfeld_110kV'],\n",
    "                    ['Sindelfingen_110kV', 'Oberjettingen_110kV'],\n",
    "                    ['Sipplingen_110kV', 'Markdorf_110kV'],\n",
    "                    ['Biberach_110kV', 'Ravensburg_110kV'],\n",
    "                    ['Goldshofe_110kV', 'Giengen_110kV']]\n",
    "\n",
    "elif h2_scenario_demand == 'TN-PtG-PtL':\n",
    "    fnb_2030_plus = [['KarlsruheWest_110kV', 'GKMannheim_110kV'],\n",
    "                    ['KarlsruheWest_110kV', 'Sindelfingen_110kV'],\n",
    "                    ['Sipplingen_110kV', 'Schmiechen_110kV'],\n",
    "                    ['Pfahlbronn_110kV', 'Giengen_110kV']]\n",
    "\n",
    "elif h2_scenario_demand == 'TN-Strom':\n",
    "    fnb_2030_plus = [['Kuppenheim_110kV', 'Lorrach_110kV'],\n",
    "                    ['KarlsruheWest_110kV', 'GKMannheim_110kV'],\n",
    "                    ['KarlsruheWest_110kV', 'Stuttgart_110kV'],\n",
    "                    ['Schmiechen_110kV', 'Laufen_an_der_Eyach_110kV'],\n",
    "                    ['Pfahlbronn_110kV', 'Giengen_110kV']]\n",
    "\n",
    "if h2_pipe_config == 'short_fnb_2030':\n",
    "    \n",
    "    for i_count in range(len(fnb_2030_plus)):\n",
    "        link_colors.loc['{}_{}_h2_pipe'.format(fnb_2030_plus[i_count][0], fnb_2030_plus[i_count][1])] = 'red'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f002ab",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "map = folium.Map(location=[48.77000, 9.18], zoom_start=7, tiles=\"OpenStreetMap\")\n",
    "\n",
    "#tooltip = \"Click me!\"\n",
    "\n",
    "# y # x\n",
    "\n",
    "for x in range(len(df_h2_buses_load)):\n",
    "    folium.Marker([df_h2_buses_load['y'][x], df_h2_buses_load['x'][x]], \n",
    "            popup=\"<i>{}_H2_bus</i>\".format(df_h2_buses_load.index[x])).add_to(map)\n",
    "\n",
    "map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c05ffb3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(\n",
    "    1, 1, subplot_kw={\"projection\": ccrs.EqualEarth()}, figsize=(10, 10)\n",
    ")\n",
    "\n",
    "network.plot(ax=ax, margin=0.08, bus_sizes = 0.0005, color_geomap=True, \n",
    "             link_colors = link_colors, line_colors = line_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed92cda",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "network.lopf(pyomo=False, solver_name='gurobi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1546c33f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "index_list = []\n",
    "capital_costs = []\n",
    "marginal_costs = []\n",
    "efficiency = []\n",
    "p_nom_opt_sum = []\n",
    "capacity = []\n",
    "\n",
    "for all_carr in list(techno_econ_data.index):\n",
    "    if all_carr in list(network.generators['carrier'].unique()):\n",
    "        index_list.append(all_carr)\n",
    "        capital_costs.append(techno_econ_data.at['{}'.format(all_carr), 'capital_costs']) \n",
    "        marginal_costs.append(techno_econ_data.at['{}'.format(all_carr), 'marginal_costs'])\n",
    "        efficiency.append(techno_econ_data.at['{}'.format(all_carr), 'efficiency'])\n",
    "        p_nom_opt_sum.append(round(network.generators[network.generators['carrier'] == '{}'.format(all_carr)]['p_nom_opt'].sum(),2))\n",
    "        capacity.append((network.generators[network.generators['carrier'] == '{}'.format(all_carr)]['p_nom'].sum()))\n",
    "        \n",
    "df_p_nom_opt_tech_cost = pd.DataFrame(index=index_list)\n",
    "df_p_nom_opt_tech_cost.index.names = ['gen_type']\n",
    "df_p_nom_opt_tech_cost['capital_costs (Euro/MW)'] = capital_costs\n",
    "df_p_nom_opt_tech_cost['marginal_costs (Euro/MWh)'] = marginal_costs\n",
    "df_p_nom_opt_tech_cost['efficiency'] = efficiency\n",
    "df_p_nom_opt_tech_cost['efficiency_store'] = ''\n",
    "df_p_nom_opt_tech_cost['efficiency_dispatch'] = ''\n",
    "df_p_nom_opt_tech_cost['p_nom_opt_sum (MW)'] = p_nom_opt_sum\n",
    "df_p_nom_opt_tech_cost['capacity (MW)'] = capacity\n",
    "\n",
    "su_index_list = []\n",
    "su_capital_costs = []\n",
    "su_marginal_costs = []\n",
    "su_efficiency_store = []\n",
    "su_efficiency_dispatch = []\n",
    "su_p_nom_opt_sum = []\n",
    "su_capacity = []\n",
    "\n",
    "for su_all_carr in list(techno_econ_data.index):\n",
    "    if su_all_carr in list(network.storage_units['carrier'].unique()):\n",
    "        su_index_list.append(su_all_carr)\n",
    "        su_capital_costs.append(techno_econ_data.at['{}'.format(su_all_carr), 'capital_costs']) \n",
    "        su_marginal_costs.append(techno_econ_data.at['{}'.format(su_all_carr), 'marginal_costs'])\n",
    "        su_efficiency_store.append(techno_econ_data.at['{}'.format(su_all_carr), 'efficiency_store'])\n",
    "        su_efficiency_dispatch.append(techno_econ_data.at['{}'.format(su_all_carr), 'efficiency_dispatch'])       \n",
    "        su_p_nom_opt_sum.append(round(network.storage_units[network.storage_units['carrier'] == '{}'.format(su_all_carr)]['p_nom_opt'].sum(),2))\n",
    "        su_capacity.append((network.storage_units[network.storage_units['carrier'] == '{}'.format(su_all_carr)]['p_nom'].sum()))\n",
    "        \n",
    "df_su_p_nom_opt_tech_cost = pd.DataFrame(index=su_index_list)\n",
    "df_su_p_nom_opt_tech_cost.index.names = ['gen_type']\n",
    "df_su_p_nom_opt_tech_cost['capital_costs (Euro/MW)'] = su_capital_costs\n",
    "df_su_p_nom_opt_tech_cost['marginal_costs (Euro/MWh)'] = su_marginal_costs\n",
    "df_su_p_nom_opt_tech_cost['efficiency'] = ''\n",
    "df_su_p_nom_opt_tech_cost['efficiency_store'] = su_efficiency_store\n",
    "df_su_p_nom_opt_tech_cost['efficiency_dispatch'] = su_efficiency_dispatch\n",
    "df_su_p_nom_opt_tech_cost['p_nom_opt_sum (MW)'] = su_p_nom_opt_sum\n",
    "df_su_p_nom_opt_tech_cost['capacity (MW)'] = su_capacity\n",
    "\n",
    "df_gen_p_nom_opt_costs = pd.concat([df_p_nom_opt_tech_cost, df_su_p_nom_opt_tech_cost])\n",
    "df_gen_p_nom_opt_costs.sort_values(by='p_nom_opt_sum (MW)', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f9bd9e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "network.links.p_nom_opt.plot.bar(ylabel='MW', figsize=(15,10))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f1af58",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "str_unit_carr = list(np.unique(list(network.stores.carrier)))\n",
    "\n",
    "df_stor_p_nom_opt = pd.DataFrame(index=str_unit_carr)\n",
    "\n",
    "str_p_nom_opt_list = []\n",
    "str_p_nom_list = []\n",
    "\n",
    "for carr_count_z in range(len(str_unit_carr)):\n",
    "    p_nom_opt_sum_z = network.stores[network.stores['carrier'] == '{}'.format(str_unit_carr[carr_count_z])]['e_nom_opt'].sum()\n",
    "    p_nom_sum_z = network.stores[network.stores['carrier'] == '{}'.format(str_unit_carr[carr_count_z])]['e_nom'].sum()\n",
    "    str_p_nom_opt_list.append(round(p_nom_opt_sum_z,2))\n",
    "    str_p_nom_list.append(round(p_nom_sum_z,2))\n",
    "    \n",
    "\n",
    "df_stor_p_nom_opt['capacity e_nom_sum (MWh)'] = str_p_nom_list\n",
    "df_stor_p_nom_opt['e_nom_opt_sum (MWh)'] = str_p_nom_opt_list  \n",
    "\n",
    "df_stor_p_nom_opt        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c89e23",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1577088",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
