{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "884f17f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pypsa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cartopy.crs as ccrs\n",
    "import folium\n",
    "from pypsa.linopt import get_var, linexpr, define_constraints\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy import distance\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bef113b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pypsa.io:Imported network 2_2040 has buses, carriers, generators, global_constraints, lines, loads, storage_units, transformers\n",
      "C:\\Users\\HP Elitebook 840\\AppData\\Local\\Temp\\ipykernel_2704\\3586908258.py:58: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\HP Elitebook 840\\AppData\\Local\\Temp\\ipykernel_2704\\3586908258.py:59: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_electrical_data(years_elect):\n",
    "    if years_elect == [2030]:\n",
    "        return \"C:/Users/work/pypsa_thesis/data/electrical/1_2030\"\n",
    "    elif years_elect == [2040]:\n",
    "        return \"C:/Users/work/pypsa_thesis/data/electrical/2_2040\"\n",
    "    elif years_elect == [2050]:\n",
    "        return \"C:/Users/work/pypsa_thesis/data/electrical/3_2050\"\n",
    "\n",
    "\n",
    "def get_hydrogen_data(scenario_h2, years_h2, h2_config):\n",
    "    if scenario_h2 == 'TN-H2-G':\n",
    "        if years_h2 == [2030]:\n",
    "            load_data = pd.read_csv(\"C:/Users/work/pypsa_thesis/data/hydrogen/TN-H2-G/BW_2030.csv\",\n",
    "                                    index_col=0)\n",
    "\n",
    "        elif years_h2 == [2040]:\n",
    "            load_data = pd.read_csv(\"C:/Users/work/pypsa_thesis/data/hydrogen/TN-H2-G/BW_2040.csv\",\n",
    "                                    index_col=0)\n",
    "\n",
    "        elif years_h2 == [2050]:\n",
    "            load_data = pd.read_csv(\"C:/Users/work/pypsa_thesis/data/hydrogen/TN-H2-G/BW_2050.csv\",\n",
    "                                    index_col=0)\n",
    "\n",
    "    elif scenario_h2 == 'TN-PtG-PtL':\n",
    "        if years_h2 == [2030]:\n",
    "            load_data = pd.read_csv(\"C:/Users/work/pypsa_thesis/data/hydrogen/TN-PtG-PtL/BW_2030.csv\",\n",
    "                                    index_col=0)\n",
    "\n",
    "        elif years_h2 == [2040]:\n",
    "            load_data = pd.read_csv(\"C:/Users/work/pypsa_thesis/data/hydrogen/TN-PtG-PtL/BW_2040.csv\",\n",
    "                                    index_col=0)\n",
    "\n",
    "        elif years_h2 == [2050]:\n",
    "            load_data = pd.read_csv(\"C:/Users/work/pypsa_thesis/data/hydrogen/TN-PtG-PtL/BW_2050.csv\",\n",
    "                                    index_col=0)\n",
    "\n",
    "    elif scenario_h2 == 'TN-Strom':\n",
    "        if years_h2 == [2030]:\n",
    "            load_data = pd.read_csv(\"C:/Users/work/pypsa_thesis/data/hydrogen/TN-Strom/BW_2030.csv\",\n",
    "                                    index_col=0)\n",
    "\n",
    "        elif years_h2 == [2040]:\n",
    "            load_data = pd.read_csv(\"C:/Users/work/pypsa_thesis/data/hydrogen/TN-Strom/BW_2040.csv\",\n",
    "                                    index_col=0)\n",
    "\n",
    "        elif years_h2 == [2050]:\n",
    "            load_data = pd.read_csv(\"C:/Users/work/pypsa_thesis/data/hydrogen/TN-Strom/BW_2050.csv\",\n",
    "                                    index_col=0)\n",
    "\n",
    "    df_h2_demand = pd.DataFrame(load_data)\n",
    "    df_h2_demand.index.names = ['location_name']\n",
    "    df_h2_demand.reset_index(inplace=True)\n",
    "    df_h2_demand.dropna(subset=['location_name'], inplace=True)\n",
    "\n",
    "    for loc_count in range(len(df_h2_demand['location_name'])):\n",
    "        geolocator = Nominatim(user_agent=\"locate_h2_demand\")\n",
    "        locate_h2_demand = geolocator.geocode(df_h2_demand['location_name'][loc_count].split(',')[0])\n",
    "        df_h2_demand['x'][loc_count] = locate_h2_demand.longitude\n",
    "        df_h2_demand['y'][loc_count] = locate_h2_demand.latitude\n",
    "\n",
    "    df_ac_loads_h2_loads_dist = pd.DataFrame(index=network.loads.index, columns=df_h2_demand['location_name'])\n",
    "\n",
    "    for city_count_x in range(len(network.loads.index)):\n",
    "        for city_count_y in range(len(df_h2_demand['location_name'])):\n",
    "            if network.loads.index[city_count_x] != df_h2_demand['location_name'][city_count_y]:\n",
    "                city_1 = (network.loads['y'][city_count_x], network.loads['x'][city_count_x])\n",
    "                city_2 = (df_h2_demand['y'][city_count_y], df_h2_demand['x'][city_count_y])\n",
    "                dist_city1_city2 = distance.distance(city_1, city_2).km\n",
    "                df_ac_loads_h2_loads_dist.at[\n",
    "                    network.loads.index[city_count_x], df_h2_demand['location_name'][city_count_y]] = dist_city1_city2\n",
    "\n",
    "    ac_loads_h2_links = []\n",
    "\n",
    "    for column_count_x in df_ac_loads_h2_loads_dist.columns:\n",
    "        for distance_count_x in range(len(df_ac_loads_h2_loads_dist[column_count_x])):\n",
    "            if df_ac_loads_h2_loads_dist[column_count_x][distance_count_x] == \\\n",
    "                    df_ac_loads_h2_loads_dist[column_count_x].min():\n",
    "                ac_loads_h2_links.append(df_ac_loads_h2_loads_dist.index[distance_count_x])\n",
    "\n",
    "    ac_loads_h2_links = list(dict.fromkeys(ac_loads_h2_links))\n",
    "\n",
    "    df_h2_buses_load = pd.DataFrame(index=ac_loads_h2_links, columns={'h2_load': [], 'x': [], 'y': []})\n",
    "\n",
    "    for buses_count in range(len(network.buses.index)):\n",
    "        for h2_buses_count in range(len(df_h2_buses_load.index)):\n",
    "            if network.buses.index[buses_count] == df_h2_buses_load.index[h2_buses_count]:\n",
    "                df_h2_buses_load['x'][h2_buses_count] = network.buses['x'][buses_count]\n",
    "                df_h2_buses_load['y'][h2_buses_count] = network.buses['y'][buses_count]\n",
    "\n",
    "    df_h2_buses_load.fillna(0, inplace=True)\n",
    "\n",
    "    for column_count_y, i_count_y in zip(df_ac_loads_h2_loads_dist.columns, range(len(df_h2_demand['location_name']))):\n",
    "        for distance_count_y in range(len(df_ac_loads_h2_loads_dist[column_count_y])):\n",
    "            if df_ac_loads_h2_loads_dist[column_count_y][distance_count_y] == \\\n",
    "                    df_ac_loads_h2_loads_dist[column_count_y].min():\n",
    "                h2_load_value = df_h2_demand[df_h2_demand['location_name'] == column_count_y]['demand_value'][\n",
    "                                    i_count_y] * 1e6  # in MWh\n",
    "                h2_demand_loc = df_ac_loads_h2_loads_dist.index[distance_count_y]\n",
    "                if df_h2_buses_load.at[h2_demand_loc, 'h2_load'] == 0:\n",
    "                    df_h2_buses_load.at[h2_demand_loc, 'h2_load'] = h2_load_value\n",
    "                else:\n",
    "                    df_h2_buses_load.at[h2_demand_loc, 'h2_load'] = df_h2_buses_load.at[h2_demand_loc, 'h2_load'] + \\\n",
    "                                                                    h2_load_value\n",
    "\n",
    "    df_h2_pipelines_dist = pd.DataFrame(index=ac_loads_h2_links, columns=ac_loads_h2_links)\n",
    "\n",
    "    for column_count_z in range(len(list(df_h2_pipelines_dist.index))):\n",
    "        for row_count_z in range(len(list(df_h2_pipelines_dist.columns))):\n",
    "            if df_h2_pipelines_dist.index[column_count_z] != df_h2_pipelines_dist.columns[row_count_z]:\n",
    "                loc_1 = (df_h2_buses_load['y'][column_count_z], df_h2_buses_load['x'][column_count_z])\n",
    "                loc_2 = (df_h2_buses_load['y'][row_count_z], df_h2_buses_load['x'][row_count_z])\n",
    "                dist_loc_1_loc_2 = distance.distance(loc_1, loc_2).km\n",
    "                df_h2_pipelines_dist.at[\n",
    "                    df_h2_pipelines_dist.columns[row_count_z], df_h2_pipelines_dist.index[column_count_z]] = \\\n",
    "                    dist_loc_1_loc_2\n",
    "\n",
    "    if h2_config == 'short':\n",
    "\n",
    "        h2_pipe_row_list = []\n",
    "        h2_bus_0_list = []\n",
    "        h2_bus_1_list = []\n",
    "        bus_0_list = []\n",
    "        bus_1_list = []\n",
    "        distance_km_list = []\n",
    "\n",
    "        for city_count_p in list(df_h2_pipelines_dist.columns):\n",
    "            for city_count_q in range(len(list(df_h2_pipelines_dist.index))):\n",
    "                if df_h2_pipelines_dist[city_count_p][city_count_q] == \\\n",
    "                        df_h2_pipelines_dist[city_count_p].min():\n",
    "                    h2_pipe_row_list.append(\n",
    "                        '{}_{}_h2_pipe'.format(city_count_p, df_h2_pipelines_dist.index[city_count_q]))\n",
    "                    h2_bus_0_list.append('{}_H2_Bus'.format(city_count_p))\n",
    "                    h2_bus_1_list.append('{}_H2_Bus'.format(df_h2_pipelines_dist.index[city_count_q]))\n",
    "                    bus_0_list.append(city_count_p)\n",
    "                    bus_1_list.append(df_h2_pipelines_dist.index[city_count_q])\n",
    "                    distance_km_list.append(df_h2_pipelines_dist[city_count_p].min())\n",
    "\n",
    "        df_h2_pipelines = pd.DataFrame(index=h2_pipe_row_list)\n",
    "        df_h2_pipelines.index.names = ['H2_pipelines']\n",
    "\n",
    "        df_h2_pipelines['bus_0'] = h2_bus_0_list\n",
    "        df_h2_pipelines['bus_1'] = h2_bus_1_list\n",
    "        df_h2_pipelines['distance_km'] = distance_km_list\n",
    "\n",
    "        df_h2_pipelines.drop_duplicates(subset=['distance_km'], inplace=True)\n",
    "\n",
    "    elif h2_config == 'all':\n",
    "\n",
    "        h2_pipe_row_list = []\n",
    "        h2_bus_0_list = []\n",
    "        h2_bus_1_list = []\n",
    "        bus_0_list = []\n",
    "        bus_1_list = []\n",
    "        distance_km_list = []\n",
    "\n",
    "        for city_count_r in list(df_h2_pipelines_dist.columns):\n",
    "            for city_count_s, i_count_s in zip(list(df_h2_pipelines_dist.index), range(len(list(df_h2_pipelines_dist.index)))):\n",
    "                if city_count_r != city_count_s:\n",
    "                    h2_pipe_row_list.append(\n",
    "                        '{}_{}_h2_pipe'.format(city_count_r, city_count_s))\n",
    "                    h2_bus_0_list.append('{}_H2_Bus'.format(city_count_r))\n",
    "                    h2_bus_1_list.append('{}_H2_Bus'.format(city_count_s))\n",
    "                    bus_0_list.append(city_count_r)\n",
    "                    bus_1_list.append(city_count_s)\n",
    "                    distance_km_list.append(df_h2_pipelines_dist[city_count_r][i_count_s])\n",
    "\n",
    "        df_h2_pipelines = pd.DataFrame(index=h2_pipe_row_list)\n",
    "        df_h2_pipelines.index.names = ['H2_pipelines']\n",
    "\n",
    "        df_h2_pipelines['bus_0'] = h2_bus_0_list\n",
    "        df_h2_pipelines['bus_1'] = h2_bus_1_list\n",
    "        df_h2_pipelines['distance_km'] = distance_km_list\n",
    "\n",
    "        df_h2_pipelines.drop_duplicates(subset=['distance_km'], inplace=True)\n",
    "\n",
    "    elif h2_config == 'short_fnb_2030':\n",
    "\n",
    "        h2_pipe_row_list = []\n",
    "        h2_bus_0_list = []\n",
    "        h2_bus_1_list = []\n",
    "        bus_0_list = []\n",
    "        bus_1_list = []\n",
    "        distance_km_list = []\n",
    "\n",
    "        for city_count_a in list(df_h2_pipelines_dist.columns):\n",
    "            for city_count_b in range(len(list(df_h2_pipelines_dist.index))):\n",
    "                if df_h2_pipelines_dist[city_count_a][city_count_b] == \\\n",
    "                        df_h2_pipelines_dist[city_count_a].min():\n",
    "                    h2_pipe_row_list.append(\n",
    "                        '{}_{}_h2_pipe'.format(city_count_a, df_h2_pipelines_dist.index[city_count_b]))\n",
    "                    h2_bus_0_list.append('{}_H2_Bus'.format(city_count_a))\n",
    "                    h2_bus_1_list.append('{}_H2_Bus'.format(df_h2_pipelines_dist.index[city_count_b]))\n",
    "                    bus_0_list.append(city_count_a)\n",
    "                    bus_1_list.append(df_h2_pipelines_dist.index[city_count_b])\n",
    "                    distance_km_list.append(df_h2_pipelines_dist[city_count_a].min())\n",
    "\n",
    "        # below connections currently for BW\n",
    "        fnb_2030_add = [['Eichstetten_110kV', 'Lorrach_110kV'],\n",
    "                        ['KarlsruheWest_110kV', 'HeidelburgSud_110kV'],\n",
    "                        ['HeidelburgSud_110kV', 'Grossgartach_110kV'],\n",
    "                        ['Grossgartach_110kV', 'Kupferzell_110kV'],\n",
    "                        ['Sindelfingen_110kV', 'Birkenfeld_110kV'],\n",
    "                        ['Sindelfingen_110kV', 'Oberjettingen_110kV'],\n",
    "                        ['Reutlingen_110kV', 'Laufen_an_der_Eyach_110kV'],\n",
    "                        ['Sipplingen_110kV', 'Markdorf_110kV'],\n",
    "                        ['Biberach_110kV', 'Ravensburg_110kV'],\n",
    "                        ['Goldshofe_110kV', 'Giengen_110kV']]\n",
    "\n",
    "        for city_add in range(len(fnb_2030_add)):\n",
    "            h2_pipe_row_list.append('{}_{}_h2_pipe'.format(fnb_2030_add[city_add][0], fnb_2030_add[city_add][1]))\n",
    "            h2_bus_0_list.append('{}_H2_Bus'.format(fnb_2030_add[city_add][0]))\n",
    "            h2_bus_1_list.append('{}_H2_Bus'.format(fnb_2030_add[city_add][1]))\n",
    "            bus_0_list.append(fnb_2030_add[city_add][0])\n",
    "            distance_km_list.append(df_h2_pipelines_dist.at[fnb_2030_add[city_add][0], fnb_2030_add[city_add][1]])\n",
    "\n",
    "        df_h2_pipelines = pd.DataFrame(index=h2_pipe_row_list)\n",
    "        df_h2_pipelines.index.names = ['H2_pipelines']\n",
    "\n",
    "        df_h2_pipelines['bus_0'] = h2_bus_0_list\n",
    "        df_h2_pipelines['bus_1'] = h2_bus_1_list\n",
    "        df_h2_pipelines['distance_km'] = distance_km_list\n",
    "\n",
    "        df_h2_pipelines.drop_duplicates(subset=['distance_km'], inplace=True)\n",
    "\n",
    "    all_bus_list = bus_0_list + bus_1_list\n",
    "    connected_list = []\n",
    "\n",
    "    for city_check in ac_loads_h2_links:\n",
    "        if city_check not in all_bus_list:\n",
    "            print('{} not connected to any bus'.format(city_check))\n",
    "        else:\n",
    "            connected_list.append('{} is connected to a H2 bus'.format(city_check))\n",
    "\n",
    "    dict_h2_data = {'h2_links': ac_loads_h2_links,\n",
    "                    'h2_dataframe': df_h2_demand,\n",
    "                    'h2_buses_load': df_h2_buses_load,\n",
    "                    'h2_pipelines': df_h2_pipelines,\n",
    "                    'h2_demand_value_total': round(sum(df_h2_demand['demand_value']) * 1e6, 2)}  # in MWh\n",
    "\n",
    "    return dict_h2_data\n",
    "\n",
    "\n",
    "# user input for:\n",
    "# years to simulate\n",
    "# which h2 demand scenario\n",
    "# which h2 pipeline connection configuration\n",
    "# resolution in 1 year simulation - current: 24 hours / daily\n",
    "\n",
    "# choose which year to simulate\n",
    "\n",
    "years = [2040]  # [2030] or [2040] or [2050]\n",
    "\n",
    "# choose which hydrogen demand scenario to simulate\n",
    "\n",
    "h2_scenario_demand = \"TN-H2-G\"  # \"TN-H2-G\" or \"TN-PtG-PtL\" or \"TN-Strom\"\n",
    "\n",
    "# choose configuration of h2 pipelines connection:\n",
    "# 'short' - buses which have h2 demand (which is h2 buses), will connect to any h2 buses in the shortest distance\n",
    "# 'all' - each h2 buses will connect to all other h2 buses regardless of short/long distances\n",
    "# 'short_fnb_2030' - connects using 'short' config first and then follows roughly similar to proposed h2 pipeline\n",
    "#                    connection based on FNB gas network development plan 2020 - 2030\n",
    "\n",
    "h2_pipe_config = 'short'\n",
    "\n",
    "# choose resolution\n",
    "\n",
    "freq = \"24\"\n",
    "\n",
    "### case - 2 ###\n",
    "\n",
    "network = pypsa.Network(get_electrical_data(years))\n",
    "\n",
    "snapshots = pd.DatetimeIndex([])\n",
    "for year in years:\n",
    "    period = pd.date_range(start='{}-01-01 00:00'.format(year),\n",
    "                           freq='{}H'.format(freq),\n",
    "                           periods=8760 / float(freq))\n",
    "    snapshots = snapshots.append(period)\n",
    "\n",
    "network.snapshots = pd.MultiIndex.from_arrays([snapshots.year, snapshots])\n",
    "\n",
    "# network.snapshots\n",
    "\n",
    "'''\n",
    "\n",
    "Nyears value depends on the snapshot resolution freq variable\n",
    "current freq = 24 with Nyears value of = 0.041666666666666664\n",
    "Change of Nyears value will affect the calculation of capital cost using pypsa-eur methodology from \n",
    "the add_electricity script\n",
    "\n",
    "Nyears = network.snapshot_weightings.objective.sum() / 8760\n",
    "Nyears\n",
    "\n",
    "costs[\"capital_cost\"] = ((annuity(costs[\"lifetime\"], costs[\"discount rate\"]) + \n",
    "                            costs[\"FOM\"]/100.) *\n",
    "                            costs[\"investment\"] * Nyears)\n",
    "                            \n",
    "'''\n",
    "\n",
    "pmaxpu_generators = network.generators[\n",
    "    (network.generators['carrier'] == 'Solar') |\n",
    "    (network.generators['carrier'] == 'Wind_Offshore') |\n",
    "    (network.generators['carrier'] == 'Wind_Onshore')]\n",
    "\n",
    "network.generators_t.p_max_pu = network.generators_t.p_max_pu.reindex(columns=pmaxpu_generators.index)\n",
    "\n",
    "network.generators_t.p_max_pu.loc[:, pmaxpu_generators.index] = pd.DataFrame(index=network.snapshots,\n",
    "                                                                             columns=pmaxpu_generators.index,\n",
    "                                                                             data=np.random.rand(len(network.snapshots),\n",
    "                                                                                                 len(pmaxpu_generators)))\n",
    "\n",
    "h2_data = get_hydrogen_data(h2_scenario_demand, years, h2_pipe_config)\n",
    "\n",
    "# connect between electrical buses and hydrogen bus via link (as electrolysis unit)\n",
    "\n",
    "df_h2_buses_load = pd.DataFrame(h2_data['h2_buses_load'])\n",
    "\n",
    "h2_buses_names = list(df_h2_buses_load.index)\n",
    "\n",
    "h2_buses = [x + '_H2_Bus' for x in h2_buses_names]\n",
    "\n",
    "network.madd('Bus',\n",
    "             h2_buses,\n",
    "             carrier='Hydrogen',\n",
    "             x=list(df_h2_buses_load['x']),\n",
    "             y=list(df_h2_buses_load['y'])\n",
    "             )\n",
    "\n",
    "# electrolysis capital cost and efficiency are based on DEA agency data and pypsa methodology calculations\n",
    "\n",
    "electrolysis_cap_cost = 0\n",
    "electrolysis_efficiency = 0\n",
    "\n",
    "if years == [2030]:\n",
    "    electrolysis_cap_cost = 1886\n",
    "    electrolysis_efficiency = 0.68\n",
    "elif years == [2040]:\n",
    "    electrolysis_cap_cost = 1238.41\n",
    "    electrolysis_efficiency = 0.72\n",
    "elif years == [2050]:\n",
    "    electrolysis_cap_cost = 1012.85\n",
    "    electrolysis_efficiency = 0.75\n",
    "\n",
    "h2_links = [s + '_Electrolysis' for s in h2_buses_names]\n",
    "\n",
    "network.madd('Link',\n",
    "             h2_links,\n",
    "             carrier='Hydrogen',\n",
    "             capital_cost=electrolysis_cap_cost,\n",
    "             p_nom_extendable=True,\n",
    "             bus0=h2_buses_names,\n",
    "             bus1=h2_buses,\n",
    "             efficiency=electrolysis_efficiency)\n",
    "\n",
    "h2_stores = [y + '_H2_Store' for y in h2_buses_names]\n",
    "\n",
    "network.madd('Store',\n",
    "             h2_stores,\n",
    "             bus=h2_buses,\n",
    "             carrier='Hydrogen',\n",
    "             e_nom_extendable=True)\n",
    "\n",
    "h2_loads = [z + '_H2_Load' for z in h2_buses_names]\n",
    "\n",
    "network.madd('Load',\n",
    "             h2_loads,\n",
    "             bus=h2_buses,\n",
    "             p_set=list(df_h2_buses_load['h2_load']),\n",
    "             carrier='Hydrogen',\n",
    "             x=list(df_h2_buses_load['x']),\n",
    "             y=list(df_h2_buses_load['y'])\n",
    "             )\n",
    "\n",
    "ac_loads = network.loads[(network.loads['carrier'] == 'AC')]\n",
    "\n",
    "network.loads_t.p_set = pd.DataFrame(index=network.snapshots,\n",
    "                                     columns=ac_loads.index,\n",
    "                                     data=1000 * np.random.rand(len(network.snapshots), len(ac_loads)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e326f1c5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pypsa.linopf:Prepare linear problem\n",
      "INFO:pypsa.linopf:Total preparation time: 5.96s\n",
      "INFO:pypsa.linopf:Solve linear problem using Gurobi solver\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read LP format model from file C:\\Users\\HPELIT~1\\AppData\\Local\\Temp\\pypsa-problem-o67y6wbe.lp\n",
      "Reading time = 2.07 seconds\n",
      "obj: 430701 rows, 171969 columns, 1197885 nonzeros\n",
      "Gurobi Optimizer version 9.5.1 build v9.5.1rc2 (win64)\n",
      "Thread count: 2 physical cores, 4 logical processors, using up to 4 threads\n",
      "Optimize a model with 430701 rows, 171969 columns and 1197885 nonzeros\n",
      "Model fingerprint: 0x77203aa8\n",
      "Coefficient statistics:\n",
      "  Matrix range     [3e-05, 4e+02]\n",
      "  Objective range  [1e+00, 1e+04]\n",
      "  Bounds range     [1e+08, 1e+08]\n",
      "  RHS range        [3e-02, 7e+06]\n",
      "\n",
      "Concurrent LP optimizer: dual simplex and barrier\n",
      "Showing barrier log only...\n",
      "\n",
      "Presolve removed 325640 rows and 69712 columns\n",
      "Presolve time: 2.14s\n",
      "Presolved: 105061 rows, 102257 columns, 626126 nonzeros\n",
      "\n",
      "Ordering time: 3.01s\n",
      "\n",
      "Barrier statistics:\n",
      " Dense cols : 148\n",
      " Free vars  : 29199\n",
      " AA' NZ     : 7.554e+05\n",
      " Factor NZ  : 5.808e+06 (roughly 130 MB of memory)\n",
      " Factor Ops : 1.064e+09 (less than 1 second per iteration)\n",
      " Threads    : 1\n",
      "\n",
      "                  Objective                Residual\n",
      "Iter       Primal          Dual         Primal    Dual     Compl     Time\n",
      "   0   7.06959798e+15 -1.18630415e+08  2.07e+13 0.00e+00  2.73e+12     6s\n",
      "   1   7.54238624e+15 -2.52237005e+13  4.07e+12 1.20e+03  9.09e+11     6s\n",
      "   2   5.73527599e+15 -2.90060380e+13  8.71e+11 3.54e+02  2.60e+11     7s\n",
      "   3   3.71905773e+15 -2.56424279e+13  2.06e+11 2.02e+02  9.56e+10     7s\n",
      "   4   1.56841259e+15 -1.17687473e+13  2.26e+10 9.63e+01  3.01e+10     8s\n",
      "   5   3.42404638e+14 -9.81220779e+11  2.30e+09 2.41e+01  3.62e+09     8s\n",
      "   6   1.50535199e+14 -4.36348260e+11  8.78e+08 1.14e+01  1.53e+09     9s\n",
      "   7   6.10086676e+13 -6.95407524e+10  3.01e+08 1.22e+01  5.54e+08     9s\n",
      "   8   3.40245618e+13  4.98210930e+10  1.57e+08 7.42e+00  2.77e+08    10s\n",
      "   9   1.06644523e+13  7.98581450e+10  4.54e+07 3.85e+00  8.30e+07    10s\n",
      "  10   2.38216356e+12  9.50259814e+10  9.27e+06 2.11e+00  1.78e+07    10s\n",
      "  11   1.12836201e+12  1.06685126e+11  3.89e+06 1.45e+00  7.93e+06    11s\n",
      "  12   4.47337166e+11  1.40077742e+11  9.54e+05 1.92e+00  2.39e+06    11s\n",
      "  13   3.33006412e+11  1.62871415e+11  5.32e+05 1.76e+00  1.33e+06    12s\n",
      "  14   2.35684449e+11  1.70183246e+11  1.89e+05 2.39e+00  5.16e+05    12s\n",
      "  15   2.21682438e+11  1.74877196e+11  1.41e+05 1.46e+00  3.69e+05    13s\n",
      "  16   2.04812068e+11  1.76829038e+11  8.04e+04 8.93e-01  2.22e+05    13s\n",
      "  17   1.94377564e+11  1.78824140e+11  4.51e+04 7.81e-01  1.24e+05    14s\n",
      "  18   1.91480899e+11  1.79392416e+11  3.50e+04 5.68e-01  9.60e+04    14s\n",
      "  19   1.86265686e+11  1.80325217e+11  1.73e+04 8.53e-01  4.74e+04    15s\n",
      "  20   1.83390180e+11  1.80998098e+11  6.35e+03 1.00e+00  1.91e+04    15s\n",
      "  21   1.82637643e+11  1.81247991e+11  3.74e+03 5.22e-01  1.11e+04    16s\n",
      "  22   1.82256487e+11  1.81385196e+11  2.40e+03 2.95e-01  6.96e+03    16s\n",
      "  23   1.82102360e+11  1.81465222e+11  1.86e+03 1.76e-01  5.03e+03    17s\n",
      "  24   1.81806294e+11  1.81502035e+11  8.19e+02 2.06e-01  2.41e+03    17s\n",
      "  25   1.81665864e+11  1.81540697e+11  3.37e+02 1.69e-01  9.79e+02    18s\n",
      "  26   1.81589764e+11  1.81561120e+11  7.15e+01 3.76e-02  2.20e+02    18s\n",
      "  27   1.81571283e+11  1.81563373e+11  1.54e+01 1.96e-02  6.08e+01    19s\n",
      "  28   1.81570772e+11  1.81564361e+11  1.39e+01 1.31e-02  4.91e+01    19s\n",
      "  29   1.81569723e+11  1.81565481e+11  1.08e+01 3.06e-03  3.22e+01    20s\n",
      "  30   1.81567242e+11  1.81565896e+11  3.25e+00 1.32e-03  1.02e+01    20s\n",
      "  31   1.81566072e+11  1.81565925e+11  1.06e-04 1.06e-03  1.08e+00    21s\n",
      "  32   1.81565965e+11  1.81565964e+11  2.82e-05 8.62e-06  6.15e-03    21s\n",
      "  33   1.81565965e+11  1.81565965e+11  9.63e-08 3.53e-08  6.15e-06    22s\n",
      "  34   1.81565965e+11  1.81565965e+11  2.16e-08 6.70e-11  6.15e-09    22s\n",
      "\n",
      "Barrier solved model in 34 iterations and 22.01 seconds (7.37 work units)\n",
      "Optimal objective 1.81565965e+11\n",
      "\n",
      "Crossover log...\n",
      "\n",
      "   55471 variables added to crossover basis                       25s\n",
      "   56054 variables added to crossover basis                       30s\n",
      "   56714 variables added to crossover basis                       35s\n",
      "   57209 variables added to crossover basis                       40s\n",
      "   57519 variables added to crossover basis                       45s\n",
      "   57729 variables added to crossover basis                       50s\n",
      "   57955 variables added to crossover basis                       55s\n",
      "   58123 variables added to crossover basis                       61s\n",
      "   58284 variables added to crossover basis                       65s\n",
      "   58496 variables added to crossover basis                       70s\n",
      "   58754 variables added to crossover basis                       75s\n",
      "   59049 variables added to crossover basis                       80s\n",
      "   59287 variables added to crossover basis                       85s\n",
      "   59525 variables added to crossover basis                       90s\n",
      "   59725 variables added to crossover basis                       95s\n"
     ]
    }
   ],
   "source": [
    "network.lopf(pyomo=False, solver_name='gurobi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c266b57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "network.generators.p_nom_opt.plot.bar(ylabel='MW', figsize=(15,10))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41c2b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_carr = list(network.carriers.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3909752e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_carr = list(np.unique(list(network.generators.carrier)))\n",
    "gen_carr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18937d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen_p_nom_opt = pd.DataFrame(index=gen_carr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fedce55",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_p_nom_opt_list = []\n",
    "gen_p_nom_list = []\n",
    "\n",
    "for carr_count_x in range(len(gen_carr)):\n",
    "    p_nom_opt_sum_x = network.generators[network.generators['carrier'] == '{}'.format(gen_carr[carr_count_x])]['p_nom_opt'].sum()\n",
    "    p_nom_sum_x = network.generators[network.generators['carrier'] == '{}'.format(gen_carr[carr_count_x])]['p_nom'].sum()\n",
    "    gen_p_nom_opt_list.append(round(p_nom_opt_sum_x,2))\n",
    "    gen_p_nom_list.append(round(p_nom_sum_x,2))\n",
    "    \n",
    "\n",
    "df_gen_p_nom_opt['capacity p_nom_sum (MW)'] = gen_p_nom_list\n",
    "df_gen_p_nom_opt['p_nom_opt_sum (MW)'] = gen_p_nom_opt_list  \n",
    "\n",
    "df_gen_p_nom_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e6bdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "network.generators.p_nom_opt.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae7be03",
   "metadata": {},
   "outputs": [],
   "source": [
    "su_unit_carr = list(np.unique(list(network.storage_units.carrier)))\n",
    "su_unit_carr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f452a65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stor_unit_p_nom_opt = pd.DataFrame(index=su_unit_carr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4417b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "su_p_nom_opt_list = []\n",
    "su_p_nom_list = []\n",
    "\n",
    "for carr_count_y in range(len(su_unit_carr)):\n",
    "    p_nom_opt_sum_y = network.storage_units[network.storage_units['carrier'] == '{}'.format(su_unit_carr[carr_count_y])]['p_nom_opt'].sum()\n",
    "    p_nom_sum_y = network.storage_units[network.storage_units['carrier'] == '{}'.format(su_unit_carr[carr_count_y])]['p_nom'].sum()\n",
    "    su_p_nom_opt_list.append(round(p_nom_opt_sum_y,2))\n",
    "    su_p_nom_list.append(round(p_nom_sum_y,2))\n",
    "    \n",
    "\n",
    "df_stor_unit_p_nom_opt['capacity p_nom_sum (MW)'] = su_p_nom_list\n",
    "df_stor_unit_p_nom_opt['p_nom_opt_sum (MW)'] = su_p_nom_opt_list  \n",
    "\n",
    "df_stor_unit_p_nom_opt        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0acc6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "network.links.p_nom_opt.plot.bar(ylabel='MW', figsize=(15,10))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6702ee06",
   "metadata": {},
   "outputs": [],
   "source": [
    "network.links.p_nom_opt.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0853f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "network.loads[network.loads[\"carrier\"] == 'Hydrogen']['p_set'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6ff0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "network.links.p_nom_opt.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a01897",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_unit_carr = list(np.unique(list(network.stores.carrier)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8821ffa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stor_p_nom_opt = pd.DataFrame(index=str_unit_carr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91359b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_p_nom_opt_list = []\n",
    "str_p_nom_list = []\n",
    "\n",
    "for carr_count_z in range(len(str_unit_carr)):\n",
    "    p_nom_opt_sum_z = network.stores[network.stores['carrier'] == '{}'.format(str_unit_carr[carr_count_z])]['e_nom_opt'].sum()\n",
    "    p_nom_sum_z = network.stores[network.stores['carrier'] == '{}'.format(str_unit_carr[carr_count_z])]['e_nom'].sum()\n",
    "    str_p_nom_opt_list.append(round(p_nom_opt_sum_z,2))\n",
    "    str_p_nom_list.append(round(p_nom_sum_z,2))\n",
    "    \n",
    "\n",
    "df_stor_p_nom_opt['capacity e_nom_sum (MWh)'] = str_p_nom_list\n",
    "df_stor_p_nom_opt['e_nom_opt_sum (MWh)'] = str_p_nom_opt_list  \n",
    "\n",
    "df_stor_p_nom_opt        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5223a7f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
